2017-11-01 09:37:08.002  INFO 11052 --- [restartedMain] com.lakala.spark.SparkApp                : Starting SparkApp on user-PC with PID 11052 (D:\IdeaProjects\spark\target\classes started by user in D:\IdeaProjects\spark)
2017-11-01 09:37:08.009  INFO 11052 --- [restartedMain] com.lakala.spark.SparkApp                : No active profile set, falling back to default profiles: default
2017-11-01 09:37:08.493  INFO 11052 --- [restartedMain] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@42c9fcb3: startup date [Wed Nov 01 09:37:08 CST 2017]; root of context hierarchy
2017-11-01 09:37:10.414  INFO 11052 --- [restartedMain] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-11-01 09:37:11.294  INFO 11052 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-11-01 09:37:11.306  INFO 11052 --- [restartedMain] o.apache.catalina.core.StandardService   : Starting service Tomcat
2017-11-01 09:37:11.307  INFO 11052 --- [restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.11
2017-11-01 09:37:11.417  INFO 11052 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/spark]  : Initializing Spring embedded WebApplicationContext
2017-11-01 09:37:11.418  INFO 11052 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2930 ms
2017-11-01 09:37:11.667  INFO 11052 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2017-11-01 09:37:11.673  INFO 11052 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'metricsFilter' to: [/*]
2017-11-01 09:37:11.673  INFO 11052 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-11-01 09:37:11.674  INFO 11052 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2017-11-01 09:37:11.674  INFO 11052 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2017-11-01 09:37:11.674  INFO 11052 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2017-11-01 09:37:11.674  INFO 11052 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'webRequestLoggingFilter' to: [/*]
2017-11-01 09:37:11.674  INFO 11052 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'applicationContextIdFilter' to: [/*]
2017-11-01 09:37:12.073  INFO 11052 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@42c9fcb3: startup date [Wed Nov 01 09:37:08 CST 2017]; root of context hierarchy
2017-11-01 09:37:12.145  INFO 11052 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/countDay]}" onto public java.lang.String com.lakala.spark.controller.DayEndCountController.countDay()
2017-11-01 09:37:12.149  INFO 11052 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-11-01 09:37:12.150  INFO 11052 --- [restartedMain] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-11-01 09:37:12.187  INFO 11052 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 09:37:12.188  INFO 11052 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 09:37:12.236  INFO 11052 --- [restartedMain] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 09:37:12.279  WARN 11052 --- [restartedMain] .t.AbstractTemplateResolverConfiguration : Cannot find template location: classpath:/templates/ (please add some templates or check your Thymeleaf configuration)
2017-11-01 09:37:12.965  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/heapdump || /heapdump.json],methods=[GET],produces=[application/octet-stream]}" onto public void org.springframework.boot.actuate.endpoint.mvc.HeapdumpMvcEndpoint.invoke(boolean,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws java.io.IOException,javax.servlet.ServletException
2017-11-01 09:37:12.966  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/dump || /dump.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2017-11-01 09:37:12.967  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/info || /info.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2017-11-01 09:37:12.967  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/trace || /trace.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2017-11-01 09:37:12.968  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/autoconfig || /autoconfig.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2017-11-01 09:37:12.968  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/logfile || /logfile.json],methods=[GET || HEAD]}" onto public void org.springframework.boot.actuate.endpoint.mvc.LogFileMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) throws javax.servlet.ServletException,java.io.IOException
2017-11-01 09:37:12.970  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.get(java.lang.String)
2017-11-01 09:37:12.971  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers/{name:.*}],methods=[POST],consumes=[application/vnd.spring-boot.actuator.v1+json || application/json],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.LoggersMvcEndpoint.set(java.lang.String,java.util.Map<java.lang.String, java.lang.String>)
2017-11-01 09:37:12.971  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/loggers || /loggers.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2017-11-01 09:37:12.972  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/mappings || /mappings.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2017-11-01 09:37:12.973  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/configprops || /configprops.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2017-11-01 09:37:12.974  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.MetricsMvcEndpoint.value(java.lang.String)
2017-11-01 09:37:12.974  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/metrics || /metrics.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2017-11-01 09:37:12.975  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/beans || /beans.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2017-11-01 09:37:12.975  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/auditevents || /auditevents.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public org.springframework.http.ResponseEntity<?> org.springframework.boot.actuate.endpoint.mvc.AuditEventsMvcEndpoint.findByPrincipalAndAfterAndType(java.lang.String,java.util.Date,java.lang.String)
2017-11-01 09:37:12.976  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env/{name:.*}],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EnvironmentMvcEndpoint.value(java.lang.String)
2017-11-01 09:37:12.976  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/env || /env.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.EndpointMvcAdapter.invoke()
2017-11-01 09:37:12.977  INFO 11052 --- [restartedMain] o.s.b.a.e.mvc.EndpointHandlerMapping     : Mapped "{[/health || /health.json],methods=[GET],produces=[application/vnd.spring-boot.actuator.v1+json || application/json]}" onto public java.lang.Object org.springframework.boot.actuate.endpoint.mvc.HealthMvcEndpoint.invoke(javax.servlet.http.HttpServletRequest,java.security.Principal)
2017-11-01 09:37:13.129  INFO 11052 --- [restartedMain] o.s.b.d.a.OptionalLiveReloadServer       : LiveReload server is running on port 35729
2017-11-01 09:37:13.193  INFO 11052 --- [restartedMain] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2017-11-01 09:37:13.203  INFO 11052 --- [restartedMain] o.s.c.support.DefaultLifecycleProcessor  : Starting beans in phase 0
2017-11-01 09:37:13.319  INFO 11052 --- [restartedMain] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-11-01 09:37:13.325  INFO 11052 --- [restartedMain] com.lakala.spark.SparkApp                : Started SparkApp in 6.304 seconds (JVM running for 7.458)
2017-11-01 11:15:26.812  INFO 9012 --- [main] com.lakala.spark.SparkApp                : Starting SparkApp on user-PC with PID 9012 (D:\IdeaProjects\spark\target\classes started by user in D:\IdeaProjects\spark)
2017-11-01 11:15:26.818  INFO 9012 --- [main] com.lakala.spark.SparkApp                : No active profile set, falling back to default profiles: default
2017-11-01 11:15:27.439  INFO 9012 --- [main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@9cb8225: startup date [Wed Nov 01 11:15:27 CST 2017]; root of context hierarchy
2017-11-01 11:15:28.852  INFO 9012 --- [main] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-11-01 11:15:29.896  INFO 9012 --- [main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-11-01 11:15:29.909  INFO 9012 --- [main] o.apache.catalina.core.StandardService   : Starting service Tomcat
2017-11-01 11:15:29.910  INFO 9012 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.11
2017-11-01 11:15:30.041  INFO 9012 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/spark]  : Initializing Spring embedded WebApplicationContext
2017-11-01 11:15:30.042  INFO 9012 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2612 ms
2017-11-01 11:15:30.204  INFO 9012 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2017-11-01 11:15:30.210  INFO 9012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-11-01 11:15:30.211  INFO 9012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2017-11-01 11:15:30.211  INFO 9012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2017-11-01 11:15:30.211  INFO 9012 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2017-11-01 11:15:30.616  INFO 9012 --- [main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@9cb8225: startup date [Wed Nov 01 11:15:27 CST 2017]; root of context hierarchy
2017-11-01 11:15:30.693  INFO 9012 --- [main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/countDay]}" onto public java.lang.String com.lakala.spark.controller.DayEndCountController.countDay()
2017-11-01 11:15:30.700  INFO 9012 --- [main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-11-01 11:15:30.700  INFO 9012 --- [main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-11-01 11:15:30.739  INFO 9012 --- [main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 11:15:30.739  INFO 9012 --- [main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 11:15:30.793  INFO 9012 --- [main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 11:15:30.851  WARN 9012 --- [main] .t.AbstractTemplateResolverConfiguration : Cannot find template location: classpath:/templates/ (please add some templates or check your Thymeleaf configuration)
2017-11-01 11:15:31.377  INFO 9012 --- [main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2017-11-01 11:15:31.443  INFO 9012 --- [main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-11-01 11:15:31.449  INFO 9012 --- [main] com.lakala.spark.SparkApp                : Started SparkApp in 5.235 seconds (JVM running for 5.949)
2017-11-01 11:16:24.001  INFO 8900 --- [main] com.lakala.spark.SparkApp                : Starting SparkApp on user-PC with PID 8900 (D:\IdeaProjects\spark\target\classes started by user in D:\IdeaProjects\spark)
2017-11-01 11:16:24.006  INFO 8900 --- [main] com.lakala.spark.SparkApp                : No active profile set, falling back to default profiles: default
2017-11-01 11:16:24.557  INFO 8900 --- [main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@9cb8225: startup date [Wed Nov 01 11:16:24 CST 2017]; root of context hierarchy
2017-11-01 11:16:26.243  INFO 8900 --- [main] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-11-01 11:16:26.949  INFO 8900 --- [main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-11-01 11:16:26.960  INFO 8900 --- [main] o.apache.catalina.core.StandardService   : Starting service Tomcat
2017-11-01 11:16:26.961  INFO 8900 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.11
2017-11-01 11:16:27.096  INFO 8900 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/spark]  : Initializing Spring embedded WebApplicationContext
2017-11-01 11:16:27.096  INFO 8900 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2545 ms
2017-11-01 11:16:27.266  INFO 8900 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2017-11-01 11:16:27.272  INFO 8900 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-11-01 11:16:27.273  INFO 8900 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2017-11-01 11:16:27.273  INFO 8900 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2017-11-01 11:16:27.274  INFO 8900 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2017-11-01 11:16:27.653  INFO 8900 --- [main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@9cb8225: startup date [Wed Nov 01 11:16:24 CST 2017]; root of context hierarchy
2017-11-01 11:16:27.727  INFO 8900 --- [main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/countDay]}" onto public java.lang.String com.lakala.spark.controller.DayEndCountController.countDay()
2017-11-01 11:16:27.732  INFO 8900 --- [main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-11-01 11:16:27.733  INFO 8900 --- [main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-11-01 11:16:27.771  INFO 8900 --- [main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 11:16:27.771  INFO 8900 --- [main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 11:16:27.821  INFO 8900 --- [main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 11:16:27.875  WARN 8900 --- [main] .t.AbstractTemplateResolverConfiguration : Cannot find template location: classpath:/templates/ (please add some templates or check your Thymeleaf configuration)
2017-11-01 11:16:28.394  INFO 8900 --- [main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2017-11-01 11:16:28.461  INFO 8900 --- [main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-11-01 11:16:28.466  INFO 8900 --- [main] com.lakala.spark.SparkApp                : Started SparkApp in 5.076 seconds (JVM running for 5.753)
2017-11-01 11:17:00.851  INFO 8900 --- [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/spark]  : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-11-01 11:17:00.852  INFO 8900 --- [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2017-11-01 11:17:00.880  INFO 8900 --- [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 28 ms
2017-11-01 11:17:01.159  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2017-11-01 11:17:01.160  WARN 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Support for Scala 2.10 is deprecated as of Spark 2.1.0
2017-11-01 11:17:01.439  WARN 8900 --- [http-nio-8080-exec-1] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-11-01 11:17:01.545  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Submitted application: spark-dayEndCount
2017-11-01 11:17:01.559  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SecurityManager         : Changing view acls to: user
2017-11-01 11:17:01.559  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SecurityManager         : Changing modify acls to: user
2017-11-01 11:17:01.560  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2017-11-01 11:17:01.561  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2017-11-01 11:17:01.562  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()
2017-11-01 11:17:01.908  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 54254.
2017-11-01 11:17:01.923  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2017-11-01 11:17:01.941  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2017-11-01 11:17:01.944  INFO 8900 --- [http-nio-8080-exec-1] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-11-01 11:17:01.944  INFO 8900 --- [http-nio-8080-exec-1] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2017-11-01 11:17:01.952  INFO 8900 --- [http-nio-8080-exec-1] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Windows\Temp\blockmgr-f98396e1-ecbc-419b-8524-e63317cc3faf
2017-11-01 11:17:01.974  INFO 8900 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1964.1 MB
2017-11-01 11:17:02.009  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2017-11-01 11:17:02.071  INFO 8900 --- [http-nio-8080-exec-1] org.spark_project.jetty.util.log         : Logging initialized @39356ms
2017-11-01 11:17:02.130  INFO 8900 --- [http-nio-8080-exec-1] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2017-11-01 11:17:02.154  INFO 8900 --- [http-nio-8080-exec-1] org.spark_project.jetty.server.Server    : Started @39441ms
2017-11-01 11:17:02.179  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.AbstractConnector       : Started ServerConnector@55885c56{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-11-01 11:17:02.180  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2017-11-01 11:17:02.206  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@219bfe9a{/jobs,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.207  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@62cc74d8{/jobs/json,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.207  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@17681c05{/jobs/job,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.208  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3cb303aa{/jobs/job/json,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.208  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6315462c{/stages,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.209  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@49ea43ff{/stages/json,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.209  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7a9a1924{/stages/stage,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.210  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4169d83c{/stages/stage/json,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.211  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@20a39691{/stages/pool,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.211  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@397e10ec{/stages/pool/json,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.212  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3ca63cfb{/storage,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.212  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@f04dc18{/storage/json,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.213  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6b074fd6{/storage/rdd,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.213  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@26f0b8ca{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.214  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4e1a24bd{/environment,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.215  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@85edb85{/environment/json,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.215  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1d4d31e1{/executors,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.216  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@108ff35e{/executors/json,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.218  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@82e5473{/executors/threadDump,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.219  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@15aaef28{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.223  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@567d406b{/static,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.224  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4d3e9d20{/,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.225  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@684ff4e9{/api,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.226  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1b51260c{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.226  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7626e525{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.228  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://10.7.36.159:4040
2017-11-01 11:17:02.313  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2017-11-01 11:17:02.338  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54263.
2017-11-01 11:17:02.339  INFO 8900 --- [http-nio-8080-exec-1] o.a.s.n.netty.NettyBlockTransferService  : Server created on 10.7.36.159:54263
2017-11-01 11:17:02.341  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-11-01 11:17:02.343  INFO 8900 --- [http-nio-8080-exec-1] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 10.7.36.159, 54263, None)
2017-11-01 11:17:02.347  INFO 8900 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 10.7.36.159:54263 with 1964.1 MB RAM, BlockManagerId(driver, 10.7.36.159, 54263, None)
2017-11-01 11:17:02.353  INFO 8900 --- [http-nio-8080-exec-1] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 10.7.36.159, 54263, None)
2017-11-01 11:17:02.354  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 10.7.36.159, 54263, None)
2017-11-01 11:17:02.373  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@55227504{/metrics/json,null,AVAILABLE,@Spark}
2017-11-01 11:17:02.764  INFO 8900 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0 stored as values in memory (estimated size 214.5 KB, free 1963.9 MB)
2017-11-01 11:17:02.832  INFO 8900 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 1963.9 MB)
2017-11-01 11:17:02.836  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_0_piece0 in memory on 10.7.36.159:54263 (size: 20.4 KB, free: 1964.1 MB)
2017-11-01 11:17:02.840  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Created broadcast 0 from textFile at DayEndCountService.java:51
2017-11-01 11:17:02.921  INFO 8900 --- [http-nio-8080-exec-1] o.apache.hadoop.mapred.FileInputFormat   : Total input paths to process : 1
2017-11-01 11:17:02.975  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:72
2017-11-01 11:17:02.990  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 0 (collect at DayEndCountService.java:72) with 1 output partitions
2017-11-01 11:17:02.990  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 0 (collect at DayEndCountService.java:72)
2017-11-01 11:17:02.991  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2017-11-01 11:17:02.992  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:17:03.003  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 0 (MapPartitionsRDD[2] at map at DayEndCountService.java:54), which has no missing parents
2017-11-01 11:17:03.025  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1 stored as values in memory (estimated size 4.0 KB, free 1963.9 MB)
2017-11-01 11:17:03.029  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.9 MB)
2017-11-01 11:17:03.030  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_1_piece0 in memory on 10.7.36.159:54263 (size: 2.4 KB, free: 1964.1 MB)
2017-11-01 11:17:03.031  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:03.045  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at map at DayEndCountService.java:54) (first 15 tasks are for partitions Vector(0))
2017-11-01 11:17:03.046  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 0.0 with 1 tasks
2017-11-01 11:17:03.091  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4871 bytes)
2017-11-01 11:17:03.097  INFO 8900 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Running task 0.0 in stage 0.0 (TID 0)
2017-11-01 11:17:03.151  INFO 8900 --- [Executor task launch worker for task 0] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TMERINFO/20171101/part-00000:0+1614075
2017-11-01 11:17:03.246  INFO 8900 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 0.0 (TID 0). 51406 bytes result sent to driver
2017-11-01 11:17:03.267  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 0.0 (TID 0) in 189 ms on localhost (executor driver) (1/1)
2017-11-01 11:17:03.270  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2017-11-01 11:17:03.275  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 0 (collect at DayEndCountService.java:72) finished in 0.211 s
2017-11-01 11:17:03.282  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 0 finished: collect at DayEndCountService.java:72, took 0.306634 s
2017-11-01 11:17:03.298  INFO 8900 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2 stored as values in memory (estimated size 214.5 KB, free 1963.7 MB)
2017-11-01 11:17:03.312  INFO 8900 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.4 KB, free 1963.6 MB)
2017-11-01 11:17:03.315  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_2_piece0 in memory on 10.7.36.159:54263 (size: 20.4 KB, free: 1964.1 MB)
2017-11-01 11:17:03.317  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Created broadcast 2 from textFile at DayEndCountService.java:77
2017-11-01 11:17:03.340  INFO 8900 --- [http-nio-8080-exec-1] o.apache.hadoop.mapred.FileInputFormat   : Total input paths to process : 2
2017-11-01 11:17:03.345  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:114
2017-11-01 11:17:03.346  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 1 (collect at DayEndCountService.java:114) with 4 output partitions
2017-11-01 11:17:03.346  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1 (collect at DayEndCountService.java:114)
2017-11-01 11:17:03.346  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2017-11-01 11:17:03.346  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:17:03.347  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1 (MapPartitionsRDD[6] at map at DayEndCountService.java:79), which has no missing parents
2017-11-01 11:17:03.349  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:17:03.354  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:17:03.354  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_3_piece0 in memory on 10.7.36.159:54263 (size: 2.4 KB, free: 1964.1 MB)
2017-11-01 11:17:03.355  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:03.356  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at map at DayEndCountService.java:79) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:17:03.356  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1.0 with 4 tasks
2017-11-01 11:17:03.357  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:17:03.358  INFO 8900 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1.0 (TID 1)
2017-11-01 11:17:03.361  INFO 8900 --- [Executor task launch worker for task 1] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:0+33554432
2017-11-01 11:17:03.670  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_1_piece0 on 10.7.36.159:54263 in memory (size: 2.4 KB, free: 1964.1 MB)
2017-11-01 11:17:04.316  INFO 8900 --- [Executor task launch worker for task 1] o.a.spark.storage.memory.MemoryStore     : Block taskresult_1 stored as bytes in memory (estimated size 1178.5 KB, free 1962.5 MB)
2017-11-01 11:17:04.318  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_1 in memory on 10.7.36.159:54263 (size: 1178.5 KB, free: 1962.9 MB)
2017-11-01 11:17:04.319  INFO 8900 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1.0 (TID 1). 1206769 bytes result sent via BlockManager)
2017-11-01 11:17:04.322  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:17:04.323  INFO 8900 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Running task 1.0 in stage 1.0 (TID 2)
2017-11-01 11:17:04.326  INFO 8900 --- [Executor task launch worker for task 2] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:33554432+21578018
2017-11-01 11:17:04.358  INFO 8900 --- [task-result-getter-1] o.a.s.n.client.TransportClientFactory    : Successfully created connection to /10.7.36.159:54263 after 23 ms (0 ms spent in bootstraps)
2017-11-01 11:17:04.560  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1.0 (TID 1) in 1203 ms on localhost (executor driver) (1/4)
2017-11-01 11:17:04.561  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_1 on 10.7.36.159:54263 in memory (size: 1178.5 KB, free: 1964.1 MB)
2017-11-01 11:17:04.840  INFO 8900 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 1.0 (TID 2). 224668 bytes result sent to driver
2017-11-01 11:17:04.841  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:17:04.842  INFO 8900 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Running task 2.0 in stage 1.0 (TID 3)
2017-11-01 11:17:04.843  INFO 8900 --- [Executor task launch worker for task 3] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:0+33554432
2017-11-01 11:17:04.854  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 1.0 (TID 2) in 532 ms on localhost (executor driver) (2/4)
2017-11-01 11:17:05.633  INFO 8900 --- [Executor task launch worker for task 3] o.a.spark.storage.memory.MemoryStore     : Block taskresult_3 stored as bytes in memory (estimated size 1178.4 KB, free 1962.5 MB)
2017-11-01 11:17:05.635  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_3 in memory on 10.7.36.159:54263 (size: 1178.4 KB, free: 1962.9 MB)
2017-11-01 11:17:05.636  INFO 8900 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 1.0 (TID 3). 1206726 bytes result sent via BlockManager)
2017-11-01 11:17:05.637  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:17:05.640  INFO 8900 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Running task 3.0 in stage 1.0 (TID 4)
2017-11-01 11:17:05.644  INFO 8900 --- [Executor task launch worker for task 4] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:33554432+21665160
2017-11-01 11:17:05.730  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 1.0 (TID 3) in 889 ms on localhost (executor driver) (3/4)
2017-11-01 11:17:05.731  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_3 on 10.7.36.159:54263 in memory (size: 1178.4 KB, free: 1964.1 MB)
2017-11-01 11:17:06.086  INFO 8900 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 1.0 (TID 4). 228073 bytes result sent to driver
2017-11-01 11:17:06.094  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 1.0 (TID 4) in 458 ms on localhost (executor driver) (4/4)
2017-11-01 11:17:06.094  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2017-11-01 11:17:06.094  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1 (collect at DayEndCountService.java:114) finished in 2.737 s
2017-11-01 11:17:06.095  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 1 finished: collect at DayEndCountService.java:114, took 2.749566 s
2017-11-01 11:17:06.114  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:192
2017-11-01 11:17:06.116  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 2 (collect at DayEndCountService.java:192) with 4 output partitions
2017-11-01 11:17:06.116  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 2 (collect at DayEndCountService.java:192)
2017-11-01 11:17:06.116  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2017-11-01 11:17:06.116  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:17:06.116  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 2 (MapPartitionsRDD[7] at filter at DayEndCountService.java:104), which has no missing parents
2017-11-01 11:17:06.118  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4 stored as values in memory (estimated size 4.3 KB, free 1963.6 MB)
2017-11-01 11:17:06.120  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.5 KB, free 1963.6 MB)
2017-11-01 11:17:06.121  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_4_piece0 in memory on 10.7.36.159:54263 (size: 2.5 KB, free: 1964.1 MB)
2017-11-01 11:17:06.122  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:06.122  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at filter at DayEndCountService.java:104) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:17:06.122  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 2.0 with 4 tasks
2017-11-01 11:17:06.124  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:17:06.124  INFO 8900 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Running task 0.0 in stage 2.0 (TID 5)
2017-11-01 11:17:06.126  INFO 8900 --- [Executor task launch worker for task 5] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:0+33554432
2017-11-01 11:17:06.866  INFO 8900 --- [Executor task launch worker for task 5] o.a.spark.storage.memory.MemoryStore     : Block taskresult_5 stored as bytes in memory (estimated size 1173.8 KB, free 1962.5 MB)
2017-11-01 11:17:06.869  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_5 in memory on 10.7.36.159:54263 (size: 1173.8 KB, free: 1962.9 MB)
2017-11-01 11:17:06.869  INFO 8900 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 2.0 (TID 5). 1201997 bytes result sent via BlockManager)
2017-11-01 11:17:06.877  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 2.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:17:06.877  INFO 8900 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Running task 1.0 in stage 2.0 (TID 6)
2017-11-01 11:17:06.880  INFO 8900 --- [Executor task launch worker for task 6] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:33554432+21578018
2017-11-01 11:17:06.949  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 2.0 (TID 5) in 825 ms on localhost (executor driver) (1/4)
2017-11-01 11:17:06.949  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_5 on 10.7.36.159:54263 in memory (size: 1173.8 KB, free: 1964.1 MB)
2017-11-01 11:17:07.366  INFO 8900 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 2.0 (TID 6). 202709 bytes result sent to driver
2017-11-01 11:17:07.366  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 2.0 (TID 7, localhost, executor driver, partition 2, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:17:07.367  INFO 8900 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Running task 2.0 in stage 2.0 (TID 7)
2017-11-01 11:17:07.368  INFO 8900 --- [Executor task launch worker for task 7] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:0+33554432
2017-11-01 11:17:07.376  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 2.0 (TID 6) in 506 ms on localhost (executor driver) (2/4)
2017-11-01 11:17:08.097  INFO 8900 --- [Executor task launch worker for task 7] o.a.spark.storage.memory.MemoryStore     : Block taskresult_7 stored as bytes in memory (estimated size 1173.7 KB, free 1962.5 MB)
2017-11-01 11:17:08.099  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_7 in memory on 10.7.36.159:54263 (size: 1173.7 KB, free: 1962.9 MB)
2017-11-01 11:17:08.100  INFO 8900 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 2.0 (TID 7). 1201868 bytes result sent via BlockManager)
2017-11-01 11:17:08.100  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 2.0 (TID 8, localhost, executor driver, partition 3, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:17:08.108  INFO 8900 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Running task 3.0 in stage 2.0 (TID 8)
2017-11-01 11:17:08.110  INFO 8900 --- [Executor task launch worker for task 8] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:33554432+21665160
2017-11-01 11:17:08.171  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 2.0 (TID 7) in 805 ms on localhost (executor driver) (3/4)
2017-11-01 11:17:08.172  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_7 on 10.7.36.159:54263 in memory (size: 1173.7 KB, free: 1964.1 MB)
2017-11-01 11:17:08.589  INFO 8900 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 2.0 (TID 8). 206114 bytes result sent to driver
2017-11-01 11:17:08.597  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 2.0 (TID 8) in 497 ms on localhost (executor driver) (4/4)
2017-11-01 11:17:08.597  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2017-11-01 11:17:08.597  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 2 (collect at DayEndCountService.java:192) finished in 2.474 s
2017-11-01 11:17:08.598  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 2 finished: collect at DayEndCountService.java:192, took 2.482945 s
2017-11-01 11:17:08.773  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:252
2017-11-01 11:17:08.778  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 8 (mapToPair at DayEndCountService.java:196)
2017-11-01 11:17:08.779  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 3 (collect at DayEndCountService.java:252) with 4 output partitions
2017-11-01 11:17:08.779  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 4 (collect at DayEndCountService.java:252)
2017-11-01 11:17:08.779  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 3)
2017-11-01 11:17:08.779  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 3)
2017-11-01 11:17:08.780  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at mapToPair at DayEndCountService.java:196), which has no missing parents
2017-11-01 11:17:08.786  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5 stored as values in memory (estimated size 6.1 KB, free 1963.6 MB)
2017-11-01 11:17:08.790  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1963.6 MB)
2017-11-01 11:17:08.792  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_5_piece0 in memory on 10.7.36.159:54263 (size: 3.2 KB, free: 1964.1 MB)
2017-11-01 11:17:08.793  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:08.795  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at mapToPair at DayEndCountService.java:196) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:17:08.795  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 3.0 with 4 tasks
2017-11-01 11:17:08.796  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:17:08.797  INFO 8900 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Running task 0.0 in stage 3.0 (TID 9)
2017-11-01 11:17:08.802  INFO 8900 --- [Executor task launch worker for task 9] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:0+33554432
2017-11-01 11:17:09.770  INFO 8900 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 3.0 (TID 9). 983 bytes result sent to driver
2017-11-01 11:17:09.770  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:17:09.771  INFO 8900 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Running task 1.0 in stage 3.0 (TID 10)
2017-11-01 11:17:09.772  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 3.0 (TID 9) in 977 ms on localhost (executor driver) (1/4)
2017-11-01 11:17:09.773  INFO 8900 --- [Executor task launch worker for task 10] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:33554432+21578018
2017-11-01 11:17:10.252  INFO 8900 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 3.0 (TID 10). 983 bytes result sent to driver
2017-11-01 11:17:10.253  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 2, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:17:10.253  INFO 8900 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Running task 2.0 in stage 3.0 (TID 11)
2017-11-01 11:17:10.253  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 3.0 (TID 10) in 483 ms on localhost (executor driver) (2/4)
2017-11-01 11:17:10.255  INFO 8900 --- [Executor task launch worker for task 11] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:0+33554432
2017-11-01 11:17:11.126  INFO 8900 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 3.0 (TID 11). 940 bytes result sent to driver
2017-11-01 11:17:11.127  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 3.0 (TID 12, localhost, executor driver, partition 3, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:17:11.127  INFO 8900 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Running task 3.0 in stage 3.0 (TID 12)
2017-11-01 11:17:11.129  INFO 8900 --- [Executor task launch worker for task 12] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:33554432+21665160
2017-11-01 11:17:11.135  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 3.0 (TID 11) in 881 ms on localhost (executor driver) (3/4)
2017-11-01 11:17:11.629  INFO 8900 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 3.0 (TID 12). 983 bytes result sent to driver
2017-11-01 11:17:11.630  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 3.0 (TID 12) in 502 ms on localhost (executor driver) (4/4)
2017-11-01 11:17:11.630  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2017-11-01 11:17:11.630  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 3 (mapToPair at DayEndCountService.java:196) finished in 2.835 s
2017-11-01 11:17:11.631  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:17:11.632  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2017-11-01 11:17:11.633  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 4)
2017-11-01 11:17:11.633  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:17:11.637  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 4 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215), which has no missing parents
2017-11-01 11:17:11.642  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6 stored as values in memory (estimated size 7.4 KB, free 1963.6 MB)
2017-11-01 11:17:11.644  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1963.6 MB)
2017-11-01 11:17:11.645  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_6_piece0 in memory on 10.7.36.159:54263 (size: 3.6 KB, free: 1964.0 MB)
2017-11-01 11:17:11.645  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:11.646  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:17:11.646  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 4.0 with 4 tasks
2017-11-01 11:17:11.649  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 4.0 (TID 13, localhost, executor driver, partition 0, ANY, 4621 bytes)
2017-11-01 11:17:11.650  INFO 8900 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Running task 0.0 in stage 4.0 (TID 13)
2017-11-01 11:17:11.660  INFO 8900 --- [Executor task launch worker for task 13] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:17:11.663  INFO 8900 --- [Executor task launch worker for task 13] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 5 ms
2017-11-01 11:17:11.852  INFO 8900 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 4.0 (TID 13). 2325 bytes result sent to driver
2017-11-01 11:17:11.853  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 4.0 (TID 14, localhost, executor driver, partition 1, ANY, 4621 bytes)
2017-11-01 11:17:11.853  INFO 8900 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Running task 1.0 in stage 4.0 (TID 14)
2017-11-01 11:17:11.855  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 4.0 (TID 13) in 206 ms on localhost (executor driver) (1/4)
2017-11-01 11:17:11.856  INFO 8900 --- [Executor task launch worker for task 14] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:17:11.856  INFO 8900 --- [Executor task launch worker for task 14] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:12.006  INFO 8900 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 4.0 (TID 14). 2376 bytes result sent to driver
2017-11-01 11:17:12.007  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 4.0 (TID 15, localhost, executor driver, partition 2, ANY, 4621 bytes)
2017-11-01 11:17:12.007  INFO 8900 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Running task 2.0 in stage 4.0 (TID 15)
2017-11-01 11:17:12.007  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 4.0 (TID 14) in 154 ms on localhost (executor driver) (2/4)
2017-11-01 11:17:12.010  INFO 8900 --- [Executor task launch worker for task 15] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:17:12.010  INFO 8900 --- [Executor task launch worker for task 15] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:12.061  INFO 8900 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 4.0 (TID 15). 2160 bytes result sent to driver
2017-11-01 11:17:12.061  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 4.0 (TID 16, localhost, executor driver, partition 3, ANY, 4621 bytes)
2017-11-01 11:17:12.062  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 4.0 (TID 15) in 56 ms on localhost (executor driver) (3/4)
2017-11-01 11:17:12.062  INFO 8900 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Running task 3.0 in stage 4.0 (TID 16)
2017-11-01 11:17:12.064  INFO 8900 --- [Executor task launch worker for task 16] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:17:12.064  INFO 8900 --- [Executor task launch worker for task 16] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:12.599  INFO 8900 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 4.0 (TID 16). 2106 bytes result sent to driver
2017-11-01 11:17:12.599  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 4.0 (TID 16) in 538 ms on localhost (executor driver) (4/4)
2017-11-01 11:17:12.600  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2017-11-01 11:17:12.600  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 4 (collect at DayEndCountService.java:252) finished in 0.952 s
2017-11-01 11:17:12.601  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 3 finished: collect at DayEndCountService.java:252, took 3.827837 s
2017-11-01 11:17:12.639  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: sortByKey at DayEndCountService.java:178
2017-11-01 11:17:12.640  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 3 (mapToPair at DayEndCountService.java:285)
2017-11-01 11:17:12.643  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 171 bytes
2017-11-01 11:17:12.704  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 11 (mapToPair at DayEndCountService.java:215)
2017-11-01 11:17:12.704  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 4 (sortByKey at DayEndCountService.java:178) with 4 output partitions
2017-11-01 11:17:12.704  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 8 (sortByKey at DayEndCountService.java:178)
2017-11-01 11:17:12.705  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 7)
2017-11-01 11:17:12.705  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 7)
2017-11-01 11:17:12.706  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 5 (MapPartitionsRDD[3] at mapToPair at DayEndCountService.java:285), which has no missing parents
2017-11-01 11:17:12.714  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7 stored as values in memory (estimated size 4.9 KB, free 1963.6 MB)
2017-11-01 11:17:12.722  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1963.6 MB)
2017-11-01 11:17:12.728  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_7_piece0 in memory on 10.7.36.159:54263 (size: 2.8 KB, free: 1964.0 MB)
2017-11-01 11:17:12.729  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:12.731  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[3] at mapToPair at DayEndCountService.java:285) (first 15 tasks are for partitions Vector(0))
2017-11-01 11:17:12.731  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 5.0 with 1 tasks
2017-11-01 11:17:12.733  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 7 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215), which has no missing parents
2017-11-01 11:17:12.734  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 5.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2017-11-01 11:17:12.734  INFO 8900 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Running task 0.0 in stage 5.0 (TID 17)
2017-11-01 11:17:12.737  INFO 8900 --- [Executor task launch worker for task 17] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TMERINFO/20171101/part-00000:0+1614075
2017-11-01 11:17:12.740  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8 stored as values in memory (estimated size 7.2 KB, free 1963.6 MB)
2017-11-01 11:17:12.742  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1963.6 MB)
2017-11-01 11:17:12.745  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_8_piece0 in memory on 10.7.36.159:54263 (size: 3.6 KB, free: 1964.0 MB)
2017-11-01 11:17:12.746  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:12.747  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:17:12.747  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 7.0 with 4 tasks
2017-11-01 11:17:12.821  INFO 8900 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 5.0 (TID 17). 940 bytes result sent to driver
2017-11-01 11:17:12.822  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 7.0 (TID 18, localhost, executor driver, partition 0, ANY, 4610 bytes)
2017-11-01 11:17:12.822  INFO 8900 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Running task 0.0 in stage 7.0 (TID 18)
2017-11-01 11:17:12.823  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 5.0 (TID 17) in 89 ms on localhost (executor driver) (1/1)
2017-11-01 11:17:12.823  INFO 8900 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 5.0, whose tasks have all completed, from pool 
2017-11-01 11:17:12.824  INFO 8900 --- [Executor task launch worker for task 18] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:17:12.824  INFO 8900 --- [Executor task launch worker for task 18] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:12.827  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 5 (mapToPair at DayEndCountService.java:285) finished in 0.091 s
2017-11-01 11:17:12.827  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:17:12.827  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set(ShuffleMapStage 7)
2017-11-01 11:17:12.827  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 8)
2017-11-01 11:17:12.827  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:17:13.014  INFO 8900 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 7.0 (TID 18). 1241 bytes result sent to driver
2017-11-01 11:17:13.014  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 7.0 (TID 19, localhost, executor driver, partition 1, ANY, 4610 bytes)
2017-11-01 11:17:13.015  INFO 8900 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Running task 1.0 in stage 7.0 (TID 19)
2017-11-01 11:17:13.015  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 7.0 (TID 18) in 193 ms on localhost (executor driver) (1/4)
2017-11-01 11:17:13.017  INFO 8900 --- [Executor task launch worker for task 19] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:17:13.017  INFO 8900 --- [Executor task launch worker for task 19] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:13.181  INFO 8900 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 7.0 (TID 19). 1241 bytes result sent to driver
2017-11-01 11:17:13.182  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 7.0 (TID 20, localhost, executor driver, partition 2, ANY, 4610 bytes)
2017-11-01 11:17:13.182  INFO 8900 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Running task 2.0 in stage 7.0 (TID 20)
2017-11-01 11:17:13.183  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 7.0 (TID 19) in 169 ms on localhost (executor driver) (2/4)
2017-11-01 11:17:13.184  INFO 8900 --- [Executor task launch worker for task 20] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:17:13.184  INFO 8900 --- [Executor task launch worker for task 20] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2017-11-01 11:17:13.261  INFO 8900 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 7.0 (TID 20). 1241 bytes result sent to driver
2017-11-01 11:17:13.261  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 7.0 (TID 21, localhost, executor driver, partition 3, ANY, 4610 bytes)
2017-11-01 11:17:13.262  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 7.0 (TID 20) in 80 ms on localhost (executor driver) (3/4)
2017-11-01 11:17:13.262  INFO 8900 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Running task 3.0 in stage 7.0 (TID 21)
2017-11-01 11:17:13.265  INFO 8900 --- [Executor task launch worker for task 21] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:17:13.265  INFO 8900 --- [Executor task launch worker for task 21] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:13.743  INFO 8900 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 7.0 (TID 21). 1241 bytes result sent to driver
2017-11-01 11:17:13.744  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 7.0 (TID 21) in 483 ms on localhost (executor driver) (4/4)
2017-11-01 11:17:13.744  INFO 8900 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2017-11-01 11:17:13.747  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 7 (mapToPair at DayEndCountService.java:215) finished in 0.997 s
2017-11-01 11:17:13.747  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:17:13.747  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2017-11-01 11:17:13.747  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 8)
2017-11-01 11:17:13.747  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:17:13.749  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 8 (MapPartitionsRDD[18] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:17:13.750  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9 stored as values in memory (estimated size 4.6 KB, free 1963.6 MB)
2017-11-01 11:17:13.751  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.5 KB, free 1963.6 MB)
2017-11-01 11:17:13.752  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_9_piece0 in memory on 10.7.36.159:54263 (size: 2.5 KB, free: 1964.0 MB)
2017-11-01 11:17:13.752  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:13.752  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 8 (MapPartitionsRDD[18] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:17:13.753  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 8.0 with 4 tasks
2017-11-01 11:17:13.754  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 8.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:17:13.754  INFO 8900 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Running task 0.0 in stage 8.0 (TID 22)
2017-11-01 11:17:13.757  INFO 8900 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:17:13.757  INFO 8900 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:13.758  INFO 8900 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:17:13.758  INFO 8900 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:13.805  INFO 8900 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 8.0 (TID 22). 2735 bytes result sent to driver
2017-11-01 11:17:13.809  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 8.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:17:13.809  INFO 8900 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Running task 1.0 in stage 8.0 (TID 23)
2017-11-01 11:17:13.811  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 8.0 (TID 22) in 58 ms on localhost (executor driver) (1/4)
2017-11-01 11:17:13.811  INFO 8900 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:17:13.811  INFO 8900 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:13.812  INFO 8900 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:17:13.812  INFO 8900 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:13.843  INFO 8900 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 8.0 (TID 23). 2715 bytes result sent to driver
2017-11-01 11:17:13.844  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 8.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:17:13.844  INFO 8900 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Running task 2.0 in stage 8.0 (TID 24)
2017-11-01 11:17:13.845  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 8.0 (TID 23) in 36 ms on localhost (executor driver) (2/4)
2017-11-01 11:17:13.846  INFO 8900 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:17:13.846  INFO 8900 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:13.847  INFO 8900 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:17:13.847  INFO 8900 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:13.877  INFO 8900 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 8.0 (TID 24). 2563 bytes result sent to driver
2017-11-01 11:17:13.877  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 8.0 (TID 25, localhost, executor driver, partition 3, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:17:13.877  INFO 8900 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Running task 3.0 in stage 8.0 (TID 25)
2017-11-01 11:17:13.877  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 8.0 (TID 24) in 33 ms on localhost (executor driver) (3/4)
2017-11-01 11:17:13.879  INFO 8900 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:17:13.879  INFO 8900 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:13.879  INFO 8900 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:17:13.879  INFO 8900 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:13.907  INFO 8900 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 8.0 (TID 25). 2552 bytes result sent to driver
2017-11-01 11:17:13.908  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 8.0 (TID 25) in 31 ms on localhost (executor driver) (4/4)
2017-11-01 11:17:13.908  INFO 8900 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2017-11-01 11:17:13.909  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 8 (sortByKey at DayEndCountService.java:178) finished in 0.156 s
2017-11-01 11:17:13.909  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 4 finished: sortByKey at DayEndCountService.java:178, took 1.269654 s
2017-11-01 11:17:13.929  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: take at DayEndCountService.java:184
2017-11-01 11:17:13.930  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 171 bytes
2017-11-01 11:17:13.931  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 168 bytes
2017-11-01 11:17:13.933  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 151 bytes
2017-11-01 11:17:13.934  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 16 (mapToPair at DayEndCountService.java:160)
2017-11-01 11:17:13.934  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 5 (take at DayEndCountService.java:184) with 1 output partitions
2017-11-01 11:17:13.934  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 13 (take at DayEndCountService.java:184)
2017-11-01 11:17:13.934  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 12)
2017-11-01 11:17:13.934  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 12)
2017-11-01 11:17:13.934  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 12 (MapPartitionsRDD[16] at mapToPair at DayEndCountService.java:160), which has no missing parents
2017-11-01 11:17:13.936  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10 stored as values in memory (estimated size 5.1 KB, free 1963.6 MB)
2017-11-01 11:17:13.939  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1963.6 MB)
2017-11-01 11:17:13.941  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_10_piece0 in memory on 10.7.36.159:54263 (size: 2.9 KB, free: 1964.0 MB)
2017-11-01 11:17:13.941  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:13.941  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[16] at mapToPair at DayEndCountService.java:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:17:13.942  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 12.0 with 4 tasks
2017-11-01 11:17:13.942  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 12.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:17:13.942  INFO 8900 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Running task 0.0 in stage 12.0 (TID 26)
2017-11-01 11:17:13.944  INFO 8900 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:17:13.945  INFO 8900 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2017-11-01 11:17:13.945  INFO 8900 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:17:13.945  INFO 8900 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:14.021  INFO 8900 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 12.0 (TID 26). 1241 bytes result sent to driver
2017-11-01 11:17:14.029  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 12.0 (TID 27, localhost, executor driver, partition 1, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:17:14.030  INFO 8900 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Running task 1.0 in stage 12.0 (TID 27)
2017-11-01 11:17:14.032  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 12.0 (TID 26) in 90 ms on localhost (executor driver) (1/4)
2017-11-01 11:17:14.034  INFO 8900 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:17:14.034  INFO 8900 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:14.034  INFO 8900 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:17:14.034  INFO 8900 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:14.103  INFO 8900 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 12.0 (TID 27). 1284 bytes result sent to driver
2017-11-01 11:17:14.103  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 12.0 (TID 28, localhost, executor driver, partition 2, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:17:14.103  INFO 8900 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Running task 2.0 in stage 12.0 (TID 28)
2017-11-01 11:17:14.104  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 12.0 (TID 27) in 74 ms on localhost (executor driver) (2/4)
2017-11-01 11:17:14.105  INFO 8900 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:17:14.106  INFO 8900 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2017-11-01 11:17:14.106  INFO 8900 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:17:14.106  INFO 8900 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:14.164  INFO 8900 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 12.0 (TID 28). 1241 bytes result sent to driver
2017-11-01 11:17:14.165  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 12.0 (TID 29, localhost, executor driver, partition 3, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:17:14.165  INFO 8900 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Running task 3.0 in stage 12.0 (TID 29)
2017-11-01 11:17:14.165  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 12.0 (TID 28) in 62 ms on localhost (executor driver) (3/4)
2017-11-01 11:17:14.167  INFO 8900 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:17:14.167  INFO 8900 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:14.168  INFO 8900 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:17:14.168  INFO 8900 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:14.231  INFO 8900 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 12.0 (TID 29). 1241 bytes result sent to driver
2017-11-01 11:17:14.232  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 12.0 (TID 29) in 67 ms on localhost (executor driver) (4/4)
2017-11-01 11:17:14.232  INFO 8900 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2017-11-01 11:17:14.232  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 12 (mapToPair at DayEndCountService.java:160) finished in 0.290 s
2017-11-01 11:17:14.232  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:17:14.232  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2017-11-01 11:17:14.232  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 13)
2017-11-01 11:17:14.232  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:17:14.233  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 13 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:17:14.234  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:17:14.236  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:17:14.236  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_11_piece0 in memory on 10.7.36.159:54263 (size: 2.4 KB, free: 1964.0 MB)
2017-11-01 11:17:14.237  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:14.237  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 13 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(0))
2017-11-01 11:17:14.237  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 13.0 with 1 tasks
2017-11-01 11:17:14.238  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 13.0 (TID 30, localhost, executor driver, partition 0, ANY, 4621 bytes)
2017-11-01 11:17:14.238  INFO 8900 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Running task 0.0 in stage 13.0 (TID 30)
2017-11-01 11:17:14.240  INFO 8900 --- [Executor task launch worker for task 30] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:17:14.240  INFO 8900 --- [Executor task launch worker for task 30] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:14.263  INFO 8900 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 13.0 (TID 30). 4222 bytes result sent to driver
2017-11-01 11:17:14.264  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 13.0 (TID 30) in 26 ms on localhost (executor driver) (1/1)
2017-11-01 11:17:14.264  INFO 8900 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 13.0, whose tasks have all completed, from pool 
2017-11-01 11:17:14.264  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 13 (take at DayEndCountService.java:184) finished in 0.026 s
2017-11-01 11:17:14.265  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 5 finished: take at DayEndCountService.java:184, took 0.335049 s
2017-11-01 11:17:14.270  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: take at DayEndCountService.java:184
2017-11-01 11:17:14.271  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 171 bytes
2017-11-01 11:17:14.271  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 168 bytes
2017-11-01 11:17:14.272  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 151 bytes
2017-11-01 11:17:14.272  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 173 bytes
2017-11-01 11:17:14.273  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 6 (take at DayEndCountService.java:184) with 1 output partitions
2017-11-01 11:17:14.273  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 18 (take at DayEndCountService.java:184)
2017-11-01 11:17:14.273  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 17)
2017-11-01 11:17:14.273  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:17:14.273  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 18 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:17:14.274  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:17:14.278  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:17:14.278  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_12_piece0 in memory on 10.7.36.159:54263 (size: 2.4 KB, free: 1964.0 MB)
2017-11-01 11:17:14.279  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:14.279  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 18 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(1))
2017-11-01 11:17:14.279  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 18.0 with 1 tasks
2017-11-01 11:17:14.279  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 18.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
2017-11-01 11:17:14.280  INFO 8900 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Running task 0.0 in stage 18.0 (TID 31)
2017-11-01 11:17:14.281  INFO 8900 --- [Executor task launch worker for task 31] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 0 non-empty blocks out of 4 blocks
2017-11-01 11:17:14.281  INFO 8900 --- [Executor task launch worker for task 31] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:14.282  INFO 8900 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 18.0 (TID 31). 1005 bytes result sent to driver
2017-11-01 11:17:14.282  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 18.0 (TID 31) in 3 ms on localhost (executor driver) (1/1)
2017-11-01 11:17:14.282  INFO 8900 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 18.0, whose tasks have all completed, from pool 
2017-11-01 11:17:14.283  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 18 (take at DayEndCountService.java:184) finished in 0.004 s
2017-11-01 11:17:14.283  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 6 finished: take at DayEndCountService.java:184, took 0.012961 s
2017-11-01 11:17:14.287  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: take at DayEndCountService.java:184
2017-11-01 11:17:14.289  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 7 (take at DayEndCountService.java:184) with 1 output partitions
2017-11-01 11:17:14.289  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 23 (take at DayEndCountService.java:184)
2017-11-01 11:17:14.289  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 22)
2017-11-01 11:17:14.289  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:17:14.289  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 23 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:17:14.290  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:17:14.292  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:17:14.292  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_13_piece0 in memory on 10.7.36.159:54263 (size: 2.4 KB, free: 1964.0 MB)
2017-11-01 11:17:14.293  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:17:14.293  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 23 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(2))
2017-11-01 11:17:14.293  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 23.0 with 1 tasks
2017-11-01 11:17:14.294  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 23.0 (TID 32, localhost, executor driver, partition 2, ANY, 4621 bytes)
2017-11-01 11:17:14.294  INFO 8900 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Running task 0.0 in stage 23.0 (TID 32)
2017-11-01 11:17:14.295  INFO 8900 --- [Executor task launch worker for task 32] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:17:14.295  INFO 8900 --- [Executor task launch worker for task 32] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:17:14.302  INFO 8900 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 23.0 (TID 32). 1574 bytes result sent to driver
2017-11-01 11:17:14.302  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 23.0 (TID 32) in 9 ms on localhost (executor driver) (1/1)
2017-11-01 11:17:14.302  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 23.0, whose tasks have all completed, from pool 
2017-11-01 11:17:14.303  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 23 (take at DayEndCountService.java:184) finished in 0.010 s
2017-11-01 11:17:14.303  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 7 finished: take at DayEndCountService.java:184, took 0.015553 s
2017-11-01 11:17:14.310  INFO 8900 --- [http-nio-8080-exec-1] o.s.jetty.server.AbstractConnector       : Stopped Spark@55885c56{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-11-01 11:17:14.312  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.ui.SparkUI              : Stopped Spark web UI at http://10.7.36.159:4040
2017-11-01 11:17:14.326  INFO 8900 --- [dispatcher-event-loop-1] o.a.s.MapOutputTrackerMasterEndpoint     : MapOutputTrackerMasterEndpoint stopped!
2017-11-01 11:17:14.584  INFO 8900 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : MemoryStore cleared
2017-11-01 11:17:14.585  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.storage.BlockManager    : BlockManager stopped
2017-11-01 11:17:14.588  INFO 8900 --- [http-nio-8080-exec-1] o.a.spark.storage.BlockManagerMaster     : BlockManagerMaster stopped
2017-11-01 11:17:14.597  INFO 8900 --- [dispatcher-event-loop-1] rdinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-11-01 11:17:14.609  INFO 8900 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Successfully stopped SparkContext
2017-11-01 11:24:14.687  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2017-11-01 11:24:14.688  WARN 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Support for Scala 2.10 is deprecated as of Spark 2.1.0
2017-11-01 11:24:14.689  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Submitted application: spark-dayEndCount
2017-11-01 11:24:14.690  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SecurityManager         : Changing view acls to: user
2017-11-01 11:24:14.690  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SecurityManager         : Changing modify acls to: user
2017-11-01 11:24:14.690  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2017-11-01 11:24:14.690  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2017-11-01 11:24:14.690  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()
2017-11-01 11:24:14.712  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 54622.
2017-11-01 11:24:14.715  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2017-11-01 11:24:14.717  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2017-11-01 11:24:14.717  INFO 8900 --- [http-nio-8080-exec-5] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-11-01 11:24:14.717  INFO 8900 --- [http-nio-8080-exec-5] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2017-11-01 11:24:14.720  INFO 8900 --- [http-nio-8080-exec-5] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Windows\Temp\blockmgr-414607bd-b309-44dd-84e7-225703c2137c
2017-11-01 11:24:14.721  INFO 8900 --- [http-nio-8080-exec-5] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1964.1 MB
2017-11-01 11:24:14.722  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2017-11-01 11:24:14.729  INFO 8900 --- [http-nio-8080-exec-5] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2017-11-01 11:24:14.731  INFO 8900 --- [http-nio-8080-exec-5] org.spark_project.jetty.server.Server    : Started @472012ms
2017-11-01 11:24:14.733  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.AbstractConnector       : Started ServerConnector@20758206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-11-01 11:24:14.733  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2017-11-01 11:24:14.734  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@72473105{/jobs,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.735  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@549493e3{/jobs/json,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.735  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@13f993c6{/jobs/job,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.735  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5d7c7500{/jobs/job/json,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.735  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@30fdca91{/stages,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.736  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1c84d8de{/stages/json,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.736  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5e90501{/stages/stage,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.736  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6ec12976{/stages/stage/json,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.736  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@fd2aeb5{/stages/pool,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.737  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7650aef1{/stages/pool/json,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.737  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5dd5eafd{/storage,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.737  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@52b947e3{/storage/json,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.738  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@25b9e94a{/storage/rdd,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.738  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@76914e93{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.738  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4757a6{/environment,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.738  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6e14d4ae{/environment/json,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.741  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4e1064d9{/executors,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.741  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@7bb4ebe7{/executors/json,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.742  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@45506414{/executors/threadDump,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.742  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@45b20666{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.742  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5403376d{/static,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.743  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3189c5f9{/,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.743  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4278d629{/api,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.744  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@50231f15{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.744  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@625a9c25{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.744  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://10.7.36.159:4040
2017-11-01 11:24:14.775  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2017-11-01 11:24:14.778  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54631.
2017-11-01 11:24:14.779  INFO 8900 --- [http-nio-8080-exec-5] o.a.s.n.netty.NettyBlockTransferService  : Server created on 10.7.36.159:54631
2017-11-01 11:24:14.779  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-11-01 11:24:14.779  INFO 8900 --- [http-nio-8080-exec-5] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 10.7.36.159, 54631, None)
2017-11-01 11:24:14.779  INFO 8900 --- [dispatcher-event-loop-0] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 10.7.36.159:54631 with 1964.1 MB RAM, BlockManagerId(driver, 10.7.36.159, 54631, None)
2017-11-01 11:24:14.779  INFO 8900 --- [http-nio-8080-exec-5] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 10.7.36.159, 54631, None)
2017-11-01 11:24:14.779  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 10.7.36.159, 54631, None)
2017-11-01 11:24:14.780  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@295671d7{/metrics/json,null,AVAILABLE,@Spark}
2017-11-01 11:24:14.786  INFO 8900 --- [http-nio-8080-exec-5] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0 stored as values in memory (estimated size 214.4 KB, free 1963.9 MB)
2017-11-01 11:24:14.794  INFO 8900 --- [http-nio-8080-exec-5] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 1963.9 MB)
2017-11-01 11:24:14.795  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_0_piece0 in memory on 10.7.36.159:54631 (size: 20.4 KB, free: 1964.1 MB)
2017-11-01 11:24:14.796  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Created broadcast 0 from textFile at DayEndCountService.java:51
2017-11-01 11:24:14.805  INFO 8900 --- [http-nio-8080-exec-5] o.apache.hadoop.mapred.FileInputFormat   : Total input paths to process : 1
2017-11-01 11:24:14.808  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:72
2017-11-01 11:24:14.809  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 0 (collect at DayEndCountService.java:72) with 1 output partitions
2017-11-01 11:24:14.809  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 0 (collect at DayEndCountService.java:72)
2017-11-01 11:24:14.809  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2017-11-01 11:24:14.809  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:24:14.809  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 0 (MapPartitionsRDD[2] at map at DayEndCountService.java:54), which has no missing parents
2017-11-01 11:24:14.810  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1 stored as values in memory (estimated size 4.0 KB, free 1963.9 MB)
2017-11-01 11:24:14.812  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.9 MB)
2017-11-01 11:24:14.813  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_1_piece0 in memory on 10.7.36.159:54631 (size: 2.4 KB, free: 1964.1 MB)
2017-11-01 11:24:14.813  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:14.814  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at map at DayEndCountService.java:54) (first 15 tasks are for partitions Vector(0))
2017-11-01 11:24:14.814  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 0.0 with 1 tasks
2017-11-01 11:24:14.814  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4871 bytes)
2017-11-01 11:24:14.815  INFO 8900 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Running task 0.0 in stage 0.0 (TID 0)
2017-11-01 11:24:14.817  INFO 8900 --- [Executor task launch worker for task 0] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TMERINFO/20171101/part-00000:0+1614075
2017-11-01 11:24:14.851  INFO 8900 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 0.0 (TID 0). 51406 bytes result sent to driver
2017-11-01 11:24:14.853  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 0.0 (TID 0) in 39 ms on localhost (executor driver) (1/1)
2017-11-01 11:24:14.853  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2017-11-01 11:24:14.854  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 0 (collect at DayEndCountService.java:72) finished in 0.039 s
2017-11-01 11:24:14.854  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 0 finished: collect at DayEndCountService.java:72, took 0.045541 s
2017-11-01 11:24:14.858  INFO 8900 --- [http-nio-8080-exec-5] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2 stored as values in memory (estimated size 214.5 KB, free 1963.7 MB)
2017-11-01 11:24:14.867  INFO 8900 --- [http-nio-8080-exec-5] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.4 KB, free 1963.6 MB)
2017-11-01 11:24:14.868  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_2_piece0 in memory on 10.7.36.159:54631 (size: 20.4 KB, free: 1964.1 MB)
2017-11-01 11:24:14.869  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Created broadcast 2 from textFile at DayEndCountService.java:77
2017-11-01 11:24:14.878  INFO 8900 --- [http-nio-8080-exec-5] o.apache.hadoop.mapred.FileInputFormat   : Total input paths to process : 2
2017-11-01 11:24:14.881  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:114
2017-11-01 11:24:14.882  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 1 (collect at DayEndCountService.java:114) with 4 output partitions
2017-11-01 11:24:14.882  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1 (collect at DayEndCountService.java:114)
2017-11-01 11:24:14.882  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2017-11-01 11:24:14.882  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:24:14.882  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1 (MapPartitionsRDD[6] at map at DayEndCountService.java:79), which has no missing parents
2017-11-01 11:24:14.883  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:24:14.885  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:24:14.886  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_3_piece0 in memory on 10.7.36.159:54631 (size: 2.4 KB, free: 1964.1 MB)
2017-11-01 11:24:14.886  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:14.886  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at map at DayEndCountService.java:79) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:24:14.886  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1.0 with 4 tasks
2017-11-01 11:24:14.887  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:24:14.887  INFO 8900 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1.0 (TID 1)
2017-11-01 11:24:14.889  INFO 8900 --- [Executor task launch worker for task 1] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:0+33554432
2017-11-01 11:24:15.353  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_1_piece0 on 10.7.36.159:54631 in memory (size: 2.4 KB, free: 1964.1 MB)
2017-11-01 11:24:15.708  INFO 8900 --- [Executor task launch worker for task 1] o.a.spark.storage.memory.MemoryStore     : Block taskresult_1 stored as bytes in memory (estimated size 1178.5 KB, free 1962.5 MB)
2017-11-01 11:24:15.709  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_1 in memory on 10.7.36.159:54631 (size: 1178.5 KB, free: 1962.9 MB)
2017-11-01 11:24:15.709  INFO 8900 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1.0 (TID 1). 1206769 bytes result sent via BlockManager)
2017-11-01 11:24:15.710  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:24:15.710  INFO 8900 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Running task 1.0 in stage 1.0 (TID 2)
2017-11-01 11:24:15.713  INFO 8900 --- [Executor task launch worker for task 2] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:33554432+21578018
2017-11-01 11:24:15.714  INFO 8900 --- [task-result-getter-1] o.a.s.n.client.TransportClientFactory    : Successfully created connection to /10.7.36.159:54631 after 2 ms (0 ms spent in bootstraps)
2017-11-01 11:24:15.781  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1.0 (TID 1) in 894 ms on localhost (executor driver) (1/4)
2017-11-01 11:24:15.781  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_1 on 10.7.36.159:54631 in memory (size: 1178.5 KB, free: 1964.1 MB)
2017-11-01 11:24:16.172  INFO 8900 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 1.0 (TID 2). 224625 bytes result sent to driver
2017-11-01 11:24:16.173  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:24:16.173  INFO 8900 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Running task 2.0 in stage 1.0 (TID 3)
2017-11-01 11:24:16.174  INFO 8900 --- [Executor task launch worker for task 3] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:0+33554432
2017-11-01 11:24:16.184  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 1.0 (TID 2) in 474 ms on localhost (executor driver) (2/4)
2017-11-01 11:24:17.212  INFO 8900 --- [Executor task launch worker for task 3] o.a.spark.storage.memory.MemoryStore     : Block taskresult_3 stored as bytes in memory (estimated size 1178.5 KB, free 1962.5 MB)
2017-11-01 11:24:17.213  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_3 in memory on 10.7.36.159:54631 (size: 1178.5 KB, free: 1962.9 MB)
2017-11-01 11:24:17.213  INFO 8900 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 1.0 (TID 3). 1206812 bytes result sent via BlockManager)
2017-11-01 11:24:17.214  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:24:17.214  INFO 8900 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Running task 3.0 in stage 1.0 (TID 4)
2017-11-01 11:24:17.216  INFO 8900 --- [Executor task launch worker for task 4] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:33554432+21665160
2017-11-01 11:24:17.296  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 1.0 (TID 3) in 1123 ms on localhost (executor driver) (3/4)
2017-11-01 11:24:17.296  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_3 on 10.7.36.159:54631 in memory (size: 1178.5 KB, free: 1964.1 MB)
2017-11-01 11:24:17.643  INFO 8900 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 1.0 (TID 4). 228030 bytes result sent to driver
2017-11-01 11:24:17.651  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 1.0 (TID 4) in 437 ms on localhost (executor driver) (4/4)
2017-11-01 11:24:17.651  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2017-11-01 11:24:17.651  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1 (collect at DayEndCountService.java:114) finished in 2.765 s
2017-11-01 11:24:17.652  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 1 finished: collect at DayEndCountService.java:114, took 2.770019 s
2017-11-01 11:24:17.662  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:192
2017-11-01 11:24:17.663  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 2 (collect at DayEndCountService.java:192) with 4 output partitions
2017-11-01 11:24:17.663  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 2 (collect at DayEndCountService.java:192)
2017-11-01 11:24:17.663  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2017-11-01 11:24:17.663  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:24:17.663  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 2 (MapPartitionsRDD[7] at filter at DayEndCountService.java:104), which has no missing parents
2017-11-01 11:24:17.664  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4 stored as values in memory (estimated size 4.3 KB, free 1963.6 MB)
2017-11-01 11:24:17.666  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.5 KB, free 1963.6 MB)
2017-11-01 11:24:17.667  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_4_piece0 in memory on 10.7.36.159:54631 (size: 2.5 KB, free: 1964.1 MB)
2017-11-01 11:24:17.668  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:17.668  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at filter at DayEndCountService.java:104) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:24:17.668  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 2.0 with 4 tasks
2017-11-01 11:24:17.669  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:24:17.669  INFO 8900 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Running task 0.0 in stage 2.0 (TID 5)
2017-11-01 11:24:17.670  INFO 8900 --- [Executor task launch worker for task 5] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:0+33554432
2017-11-01 11:24:18.493  INFO 8900 --- [Executor task launch worker for task 5] o.a.spark.storage.memory.MemoryStore     : Block taskresult_5 stored as bytes in memory (estimated size 1173.7 KB, free 1962.5 MB)
2017-11-01 11:24:18.495  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_5 in memory on 10.7.36.159:54631 (size: 1173.7 KB, free: 1962.9 MB)
2017-11-01 11:24:18.495  INFO 8900 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 2.0 (TID 5). 1201868 bytes result sent via BlockManager)
2017-11-01 11:24:18.496  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 2.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:24:18.496  INFO 8900 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Running task 1.0 in stage 2.0 (TID 6)
2017-11-01 11:24:18.501  INFO 8900 --- [Executor task launch worker for task 6] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:33554432+21578018
2017-11-01 11:24:18.611  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 2.0 (TID 5) in 942 ms on localhost (executor driver) (1/4)
2017-11-01 11:24:18.612  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_5 on 10.7.36.159:54631 in memory (size: 1173.7 KB, free: 1964.1 MB)
2017-11-01 11:24:18.998  INFO 8900 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 2.0 (TID 6). 202709 bytes result sent to driver
2017-11-01 11:24:18.998  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 2.0 (TID 7, localhost, executor driver, partition 2, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:24:18.999  INFO 8900 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Running task 2.0 in stage 2.0 (TID 7)
2017-11-01 11:24:19.000  INFO 8900 --- [Executor task launch worker for task 7] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:0+33554432
2017-11-01 11:24:19.007  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 2.0 (TID 6) in 511 ms on localhost (executor driver) (2/4)
2017-11-01 11:24:19.705  INFO 8900 --- [Executor task launch worker for task 7] o.a.spark.storage.memory.MemoryStore     : Block taskresult_7 stored as bytes in memory (estimated size 1173.7 KB, free 1962.5 MB)
2017-11-01 11:24:19.706  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_7 in memory on 10.7.36.159:54631 (size: 1173.7 KB, free: 1962.9 MB)
2017-11-01 11:24:19.706  INFO 8900 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 2.0 (TID 7). 1201911 bytes result sent via BlockManager)
2017-11-01 11:24:19.706  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 2.0 (TID 8, localhost, executor driver, partition 3, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:24:19.707  INFO 8900 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Running task 3.0 in stage 2.0 (TID 8)
2017-11-01 11:24:19.708  INFO 8900 --- [Executor task launch worker for task 8] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:33554432+21665160
2017-11-01 11:24:19.759  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 2.0 (TID 7) in 761 ms on localhost (executor driver) (3/4)
2017-11-01 11:24:19.760  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_7 on 10.7.36.159:54631 in memory (size: 1173.7 KB, free: 1964.1 MB)
2017-11-01 11:24:20.130  INFO 8900 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 2.0 (TID 8). 206114 bytes result sent to driver
2017-11-01 11:24:20.137  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 2.0 (TID 8) in 431 ms on localhost (executor driver) (4/4)
2017-11-01 11:24:20.137  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2017-11-01 11:24:20.138  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 2 (collect at DayEndCountService.java:192) finished in 2.470 s
2017-11-01 11:24:20.138  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 2 finished: collect at DayEndCountService.java:192, took 2.475709 s
2017-11-01 11:24:20.227  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:252
2017-11-01 11:24:20.228  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 8 (mapToPair at DayEndCountService.java:196)
2017-11-01 11:24:20.228  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 3 (collect at DayEndCountService.java:252) with 4 output partitions
2017-11-01 11:24:20.228  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 4 (collect at DayEndCountService.java:252)
2017-11-01 11:24:20.228  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 3)
2017-11-01 11:24:20.228  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 3)
2017-11-01 11:24:20.228  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at mapToPair at DayEndCountService.java:196), which has no missing parents
2017-11-01 11:24:20.230  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5 stored as values in memory (estimated size 6.1 KB, free 1963.6 MB)
2017-11-01 11:24:20.232  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1963.6 MB)
2017-11-01 11:24:20.233  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_5_piece0 in memory on 10.7.36.159:54631 (size: 3.2 KB, free: 1964.1 MB)
2017-11-01 11:24:20.234  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:20.235  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at mapToPair at DayEndCountService.java:196) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:24:20.235  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 3.0 with 4 tasks
2017-11-01 11:24:20.235  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:24:20.236  INFO 8900 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Running task 0.0 in stage 3.0 (TID 9)
2017-11-01 11:24:20.237  INFO 8900 --- [Executor task launch worker for task 9] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:0+33554432
2017-11-01 11:24:21.057  INFO 8900 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 3.0 (TID 9). 940 bytes result sent to driver
2017-11-01 11:24:21.058  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:24:21.058  INFO 8900 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Running task 1.0 in stage 3.0 (TID 10)
2017-11-01 11:24:21.058  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 3.0 (TID 9) in 823 ms on localhost (executor driver) (1/4)
2017-11-01 11:24:21.059  INFO 8900 --- [Executor task launch worker for task 10] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:33554432+21578018
2017-11-01 11:24:21.554  INFO 8900 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 3.0 (TID 10). 940 bytes result sent to driver
2017-11-01 11:24:21.555  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 2, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:24:21.555  INFO 8900 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Running task 2.0 in stage 3.0 (TID 11)
2017-11-01 11:24:21.555  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 3.0 (TID 10) in 498 ms on localhost (executor driver) (2/4)
2017-11-01 11:24:21.557  INFO 8900 --- [Executor task launch worker for task 11] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:0+33554432
2017-11-01 11:24:22.297  INFO 8900 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 3.0 (TID 11). 983 bytes result sent to driver
2017-11-01 11:24:22.297  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 3.0 (TID 12, localhost, executor driver, partition 3, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:24:22.298  INFO 8900 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Running task 3.0 in stage 3.0 (TID 12)
2017-11-01 11:24:22.298  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 3.0 (TID 11) in 743 ms on localhost (executor driver) (3/4)
2017-11-01 11:24:22.299  INFO 8900 --- [Executor task launch worker for task 12] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:33554432+21665160
2017-11-01 11:24:22.723  INFO 8900 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 3.0 (TID 12). 940 bytes result sent to driver
2017-11-01 11:24:22.724  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 3.0 (TID 12) in 427 ms on localhost (executor driver) (4/4)
2017-11-01 11:24:22.724  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2017-11-01 11:24:22.724  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 3 (mapToPair at DayEndCountService.java:196) finished in 2.489 s
2017-11-01 11:24:22.724  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:24:22.724  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2017-11-01 11:24:22.724  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 4)
2017-11-01 11:24:22.724  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:24:22.725  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 4 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215), which has no missing parents
2017-11-01 11:24:22.726  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6 stored as values in memory (estimated size 7.4 KB, free 1963.6 MB)
2017-11-01 11:24:22.727  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1963.6 MB)
2017-11-01 11:24:22.727  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_6_piece0 in memory on 10.7.36.159:54631 (size: 3.6 KB, free: 1964.0 MB)
2017-11-01 11:24:22.728  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:22.728  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:24:22.728  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 4.0 with 4 tasks
2017-11-01 11:24:22.729  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 4.0 (TID 13, localhost, executor driver, partition 0, ANY, 4621 bytes)
2017-11-01 11:24:22.729  INFO 8900 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Running task 0.0 in stage 4.0 (TID 13)
2017-11-01 11:24:22.731  INFO 8900 --- [Executor task launch worker for task 13] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:24:22.731  INFO 8900 --- [Executor task launch worker for task 13] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:22.934  INFO 8900 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 4.0 (TID 13). 2325 bytes result sent to driver
2017-11-01 11:24:22.935  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 4.0 (TID 14, localhost, executor driver, partition 1, ANY, 4621 bytes)
2017-11-01 11:24:22.935  INFO 8900 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Running task 1.0 in stage 4.0 (TID 14)
2017-11-01 11:24:22.936  INFO 8900 --- [Executor task launch worker for task 14] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:24:22.939  INFO 8900 --- [Executor task launch worker for task 14] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 3 ms
2017-11-01 11:24:22.938  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 4.0 (TID 13) in 209 ms on localhost (executor driver) (1/4)
2017-11-01 11:24:23.119  INFO 8900 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 4.0 (TID 14). 2376 bytes result sent to driver
2017-11-01 11:24:23.119  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 4.0 (TID 15, localhost, executor driver, partition 2, ANY, 4621 bytes)
2017-11-01 11:24:23.119  INFO 8900 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Running task 2.0 in stage 4.0 (TID 15)
2017-11-01 11:24:23.119  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 4.0 (TID 14) in 184 ms on localhost (executor driver) (2/4)
2017-11-01 11:24:23.121  INFO 8900 --- [Executor task launch worker for task 15] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:24:23.121  INFO 8900 --- [Executor task launch worker for task 15] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:23.198  INFO 8900 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 4.0 (TID 15). 2160 bytes result sent to driver
2017-11-01 11:24:23.198  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 4.0 (TID 16, localhost, executor driver, partition 3, ANY, 4621 bytes)
2017-11-01 11:24:23.199  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 4.0 (TID 15) in 80 ms on localhost (executor driver) (3/4)
2017-11-01 11:24:23.199  INFO 8900 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Running task 3.0 in stage 4.0 (TID 16)
2017-11-01 11:24:23.201  INFO 8900 --- [Executor task launch worker for task 16] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:24:23.201  INFO 8900 --- [Executor task launch worker for task 16] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2017-11-01 11:24:23.804  INFO 8900 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 4.0 (TID 16). 2106 bytes result sent to driver
2017-11-01 11:24:23.805  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 4.0 (TID 16) in 607 ms on localhost (executor driver) (4/4)
2017-11-01 11:24:23.806  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2017-11-01 11:24:23.806  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 4 (collect at DayEndCountService.java:252) finished in 1.078 s
2017-11-01 11:24:23.806  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 3 finished: collect at DayEndCountService.java:252, took 3.578791 s
2017-11-01 11:24:23.829  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Starting job: sortByKey at DayEndCountService.java:178
2017-11-01 11:24:23.830  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 171 bytes
2017-11-01 11:24:23.830  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 11 (mapToPair at DayEndCountService.java:215)
2017-11-01 11:24:23.831  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 3 (mapToPair at DayEndCountService.java:285)
2017-11-01 11:24:23.831  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 4 (sortByKey at DayEndCountService.java:178) with 4 output partitions
2017-11-01 11:24:23.831  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 8 (sortByKey at DayEndCountService.java:178)
2017-11-01 11:24:23.831  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 6, ShuffleMapStage 7)
2017-11-01 11:24:23.831  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 6, ShuffleMapStage 7)
2017-11-01 11:24:23.831  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 6 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215), which has no missing parents
2017-11-01 11:24:23.833  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7 stored as values in memory (estimated size 7.2 KB, free 1963.6 MB)
2017-11-01 11:24:23.835  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1963.6 MB)
2017-11-01 11:24:23.837  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_7_piece0 in memory on 10.7.36.159:54631 (size: 3.6 KB, free: 1964.0 MB)
2017-11-01 11:24:23.837  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:23.837  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:24:23.837  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 6.0 with 4 tasks
2017-11-01 11:24:23.838  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 7 (MapPartitionsRDD[3] at mapToPair at DayEndCountService.java:285), which has no missing parents
2017-11-01 11:24:23.838  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 6.0 (TID 17, localhost, executor driver, partition 0, ANY, 4610 bytes)
2017-11-01 11:24:23.838  INFO 8900 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Running task 0.0 in stage 6.0 (TID 17)
2017-11-01 11:24:23.839  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8 stored as values in memory (estimated size 4.9 KB, free 1963.6 MB)
2017-11-01 11:24:23.840  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1963.6 MB)
2017-11-01 11:24:23.841  INFO 8900 --- [Executor task launch worker for task 17] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:24:23.841  INFO 8900 --- [Executor task launch worker for task 17] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2017-11-01 11:24:23.841  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_8_piece0 in memory on 10.7.36.159:54631 (size: 2.8 KB, free: 1964.0 MB)
2017-11-01 11:24:23.842  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:23.842  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[3] at mapToPair at DayEndCountService.java:285) (first 15 tasks are for partitions Vector(0))
2017-11-01 11:24:23.842  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 7.0 with 1 tasks
2017-11-01 11:24:24.091  INFO 8900 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 6.0 (TID 17). 1241 bytes result sent to driver
2017-11-01 11:24:24.092  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 6.0 (TID 18, localhost, executor driver, partition 1, ANY, 4610 bytes)
2017-11-01 11:24:24.093  INFO 8900 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Running task 1.0 in stage 6.0 (TID 18)
2017-11-01 11:24:24.093  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 6.0 (TID 17) in 255 ms on localhost (executor driver) (1/4)
2017-11-01 11:24:24.095  INFO 8900 --- [Executor task launch worker for task 18] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:24:24.095  INFO 8900 --- [Executor task launch worker for task 18] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:24.286  INFO 8900 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 6.0 (TID 18). 1241 bytes result sent to driver
2017-11-01 11:24:24.290  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 6.0 (TID 19, localhost, executor driver, partition 2, ANY, 4610 bytes)
2017-11-01 11:24:24.291  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_6_piece0 on 10.7.36.159:54631 in memory (size: 3.6 KB, free: 1964.0 MB)
2017-11-01 11:24:24.291  INFO 8900 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Running task 2.0 in stage 6.0 (TID 19)
2017-11-01 11:24:24.291  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 6.0 (TID 18) in 199 ms on localhost (executor driver) (2/4)
2017-11-01 11:24:24.293  INFO 8900 --- [Executor task launch worker for task 19] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:24:24.293  INFO 8900 --- [Executor task launch worker for task 19] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:24.393  INFO 8900 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 6.0 (TID 19). 1241 bytes result sent to driver
2017-11-01 11:24:24.394  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 6.0 (TID 20, localhost, executor driver, partition 3, ANY, 4610 bytes)
2017-11-01 11:24:24.395  INFO 8900 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Running task 3.0 in stage 6.0 (TID 20)
2017-11-01 11:24:24.395  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 6.0 (TID 19) in 105 ms on localhost (executor driver) (3/4)
2017-11-01 11:24:24.397  INFO 8900 --- [Executor task launch worker for task 20] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:24:24.397  INFO 8900 --- [Executor task launch worker for task 20] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:24.967  INFO 8900 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 6.0 (TID 20). 1241 bytes result sent to driver
2017-11-01 11:24:24.968  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 7.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2017-11-01 11:24:24.968  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 6.0 (TID 20) in 574 ms on localhost (executor driver) (4/4)
2017-11-01 11:24:24.968  INFO 8900 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Running task 0.0 in stage 7.0 (TID 21)
2017-11-01 11:24:24.968  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2017-11-01 11:24:24.969  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 6 (mapToPair at DayEndCountService.java:215) finished in 1.131 s
2017-11-01 11:24:24.969  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:24:24.969  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set(ShuffleMapStage 7)
2017-11-01 11:24:24.969  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 8)
2017-11-01 11:24:24.969  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:24:24.970  INFO 8900 --- [Executor task launch worker for task 21] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TMERINFO/20171101/part-00000:0+1614075
2017-11-01 11:24:25.018  INFO 8900 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 7.0 (TID 21). 940 bytes result sent to driver
2017-11-01 11:24:25.019  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 7.0 (TID 21) in 51 ms on localhost (executor driver) (1/1)
2017-11-01 11:24:25.019  INFO 8900 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2017-11-01 11:24:25.019  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 7 (mapToPair at DayEndCountService.java:285) finished in 1.177 s
2017-11-01 11:24:25.020  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:24:25.020  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2017-11-01 11:24:25.020  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 8)
2017-11-01 11:24:25.020  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:24:25.020  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 8 (MapPartitionsRDD[18] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:24:25.021  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9 stored as values in memory (estimated size 4.6 KB, free 1963.6 MB)
2017-11-01 11:24:25.022  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.5 KB, free 1963.6 MB)
2017-11-01 11:24:25.023  INFO 8900 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_9_piece0 in memory on 10.7.36.159:54631 (size: 2.5 KB, free: 1964.0 MB)
2017-11-01 11:24:25.023  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:25.025  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 8 (MapPartitionsRDD[18] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:24:25.025  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 8.0 with 4 tasks
2017-11-01 11:24:25.025  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 8.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:24:25.025  INFO 8900 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Running task 0.0 in stage 8.0 (TID 22)
2017-11-01 11:24:25.027  INFO 8900 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:24:25.027  INFO 8900 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.027  INFO 8900 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:24:25.027  INFO 8900 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.064  INFO 8900 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 8.0 (TID 22). 2692 bytes result sent to driver
2017-11-01 11:24:25.065  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 8.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:24:25.065  INFO 8900 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Running task 1.0 in stage 8.0 (TID 23)
2017-11-01 11:24:25.066  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 8.0 (TID 22) in 41 ms on localhost (executor driver) (1/4)
2017-11-01 11:24:25.067  INFO 8900 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:24:25.067  INFO 8900 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.067  INFO 8900 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:24:25.067  INFO 8900 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.108  INFO 8900 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 8.0 (TID 23). 2715 bytes result sent to driver
2017-11-01 11:24:25.108  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 8.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:24:25.109  INFO 8900 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Running task 2.0 in stage 8.0 (TID 24)
2017-11-01 11:24:25.109  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 8.0 (TID 23) in 44 ms on localhost (executor driver) (2/4)
2017-11-01 11:24:25.110  INFO 8900 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:24:25.110  INFO 8900 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.110  INFO 8900 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:24:25.110  INFO 8900 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.148  INFO 8900 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 8.0 (TID 24). 2563 bytes result sent to driver
2017-11-01 11:24:25.148  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 8.0 (TID 25, localhost, executor driver, partition 3, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:24:25.149  INFO 8900 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Running task 3.0 in stage 8.0 (TID 25)
2017-11-01 11:24:25.149  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 8.0 (TID 24) in 41 ms on localhost (executor driver) (3/4)
2017-11-01 11:24:25.150  INFO 8900 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:24:25.150  INFO 8900 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.150  INFO 8900 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:24:25.150  INFO 8900 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.192  INFO 8900 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 8.0 (TID 25). 2509 bytes result sent to driver
2017-11-01 11:24:25.192  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 8.0 (TID 25) in 44 ms on localhost (executor driver) (4/4)
2017-11-01 11:24:25.193  INFO 8900 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2017-11-01 11:24:25.193  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 8 (sortByKey at DayEndCountService.java:178) finished in 0.168 s
2017-11-01 11:24:25.193  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 4 finished: sortByKey at DayEndCountService.java:178, took 1.363959 s
2017-11-01 11:24:25.208  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Starting job: take at DayEndCountService.java:184
2017-11-01 11:24:25.209  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 171 bytes
2017-11-01 11:24:25.209  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 151 bytes
2017-11-01 11:24:25.209  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 168 bytes
2017-11-01 11:24:25.210  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 16 (mapToPair at DayEndCountService.java:160)
2017-11-01 11:24:25.210  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 5 (take at DayEndCountService.java:184) with 1 output partitions
2017-11-01 11:24:25.210  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 13 (take at DayEndCountService.java:184)
2017-11-01 11:24:25.210  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 12)
2017-11-01 11:24:25.210  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 12)
2017-11-01 11:24:25.211  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 12 (MapPartitionsRDD[16] at mapToPair at DayEndCountService.java:160), which has no missing parents
2017-11-01 11:24:25.212  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10 stored as values in memory (estimated size 5.1 KB, free 1963.6 MB)
2017-11-01 11:24:25.214  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1963.6 MB)
2017-11-01 11:24:25.215  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_10_piece0 in memory on 10.7.36.159:54631 (size: 2.9 KB, free: 1964.0 MB)
2017-11-01 11:24:25.215  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:25.216  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[16] at mapToPair at DayEndCountService.java:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:24:25.216  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 12.0 with 4 tasks
2017-11-01 11:24:25.216  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 12.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:24:25.217  INFO 8900 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Running task 0.0 in stage 12.0 (TID 26)
2017-11-01 11:24:25.218  INFO 8900 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:24:25.219  INFO 8900 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2017-11-01 11:24:25.219  INFO 8900 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:24:25.219  INFO 8900 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.288  INFO 8900 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 12.0 (TID 26). 1241 bytes result sent to driver
2017-11-01 11:24:25.289  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 12.0 (TID 27, localhost, executor driver, partition 1, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:24:25.289  INFO 8900 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Running task 1.0 in stage 12.0 (TID 27)
2017-11-01 11:24:25.289  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 12.0 (TID 26) in 73 ms on localhost (executor driver) (1/4)
2017-11-01 11:24:25.290  INFO 8900 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:24:25.290  INFO 8900 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.291  INFO 8900 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:24:25.291  INFO 8900 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.363  INFO 8900 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 12.0 (TID 27). 1241 bytes result sent to driver
2017-11-01 11:24:25.363  INFO 8900 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 12.0 (TID 28, localhost, executor driver, partition 2, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:24:25.364  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 12.0 (TID 27) in 76 ms on localhost (executor driver) (2/4)
2017-11-01 11:24:25.364  INFO 8900 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Running task 2.0 in stage 12.0 (TID 28)
2017-11-01 11:24:25.366  INFO 8900 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:24:25.366  INFO 8900 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.366  INFO 8900 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:24:25.366  INFO 8900 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.431  INFO 8900 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 12.0 (TID 28). 1241 bytes result sent to driver
2017-11-01 11:24:25.432  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 12.0 (TID 29, localhost, executor driver, partition 3, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:24:25.432  INFO 8900 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Running task 3.0 in stage 12.0 (TID 29)
2017-11-01 11:24:25.432  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 12.0 (TID 28) in 69 ms on localhost (executor driver) (3/4)
2017-11-01 11:24:25.434  INFO 8900 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:24:25.434  INFO 8900 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.435  INFO 8900 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:24:25.435  INFO 8900 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.493  INFO 8900 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 12.0 (TID 29). 1241 bytes result sent to driver
2017-11-01 11:24:25.493  INFO 8900 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 12.0 (TID 29) in 61 ms on localhost (executor driver) (4/4)
2017-11-01 11:24:25.493  INFO 8900 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2017-11-01 11:24:25.494  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 12 (mapToPair at DayEndCountService.java:160) finished in 0.278 s
2017-11-01 11:24:25.494  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:24:25.494  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2017-11-01 11:24:25.494  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 13)
2017-11-01 11:24:25.494  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:24:25.494  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 13 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:24:25.495  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:24:25.496  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:24:25.497  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_11_piece0 in memory on 10.7.36.159:54631 (size: 2.4 KB, free: 1964.0 MB)
2017-11-01 11:24:25.497  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:25.498  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 13 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(0))
2017-11-01 11:24:25.498  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 13.0 with 1 tasks
2017-11-01 11:24:25.498  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 13.0 (TID 30, localhost, executor driver, partition 0, ANY, 4621 bytes)
2017-11-01 11:24:25.499  INFO 8900 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Running task 0.0 in stage 13.0 (TID 30)
2017-11-01 11:24:25.500  INFO 8900 --- [Executor task launch worker for task 30] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:24:25.501  INFO 8900 --- [Executor task launch worker for task 30] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2017-11-01 11:24:25.506  INFO 8900 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 13.0 (TID 30). 4222 bytes result sent to driver
2017-11-01 11:24:25.507  INFO 8900 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 13.0 (TID 30) in 9 ms on localhost (executor driver) (1/1)
2017-11-01 11:24:25.507  INFO 8900 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 13.0, whose tasks have all completed, from pool 
2017-11-01 11:24:25.507  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 13 (take at DayEndCountService.java:184) finished in 0.009 s
2017-11-01 11:24:25.507  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 5 finished: take at DayEndCountService.java:184, took 0.299489 s
2017-11-01 11:24:25.511  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Starting job: take at DayEndCountService.java:184
2017-11-01 11:24:25.513  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 171 bytes
2017-11-01 11:24:25.513  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 151 bytes
2017-11-01 11:24:25.513  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 168 bytes
2017-11-01 11:24:25.514  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 173 bytes
2017-11-01 11:24:25.514  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 6 (take at DayEndCountService.java:184) with 1 output partitions
2017-11-01 11:24:25.514  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 18 (take at DayEndCountService.java:184)
2017-11-01 11:24:25.514  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 17)
2017-11-01 11:24:25.515  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:24:25.515  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 18 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:24:25.517  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:24:25.518  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:24:25.519  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_12_piece0 in memory on 10.7.36.159:54631 (size: 2.4 KB, free: 1964.0 MB)
2017-11-01 11:24:25.519  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:25.519  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 18 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(1))
2017-11-01 11:24:25.519  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 18.0 with 1 tasks
2017-11-01 11:24:25.520  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 18.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
2017-11-01 11:24:25.520  INFO 8900 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Running task 0.0 in stage 18.0 (TID 31)
2017-11-01 11:24:25.521  INFO 8900 --- [Executor task launch worker for task 31] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 0 non-empty blocks out of 4 blocks
2017-11-01 11:24:25.521  INFO 8900 --- [Executor task launch worker for task 31] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.522  INFO 8900 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 18.0 (TID 31). 962 bytes result sent to driver
2017-11-01 11:24:25.522  INFO 8900 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 18.0 (TID 31) in 2 ms on localhost (executor driver) (1/1)
2017-11-01 11:24:25.522  INFO 8900 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 18.0, whose tasks have all completed, from pool 
2017-11-01 11:24:25.522  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 18 (take at DayEndCountService.java:184) finished in 0.003 s
2017-11-01 11:24:25.523  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 6 finished: take at DayEndCountService.java:184, took 0.011074 s
2017-11-01 11:24:25.526  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Starting job: take at DayEndCountService.java:184
2017-11-01 11:24:25.528  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 7 (take at DayEndCountService.java:184) with 1 output partitions
2017-11-01 11:24:25.528  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 23 (take at DayEndCountService.java:184)
2017-11-01 11:24:25.528  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 22)
2017-11-01 11:24:25.528  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:24:25.528  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 23 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:24:25.529  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:24:25.531  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:24:25.533  INFO 8900 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_13_piece0 in memory on 10.7.36.159:54631 (size: 2.4 KB, free: 1964.0 MB)
2017-11-01 11:24:25.533  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:24:25.533  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 23 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(2))
2017-11-01 11:24:25.533  INFO 8900 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 23.0 with 1 tasks
2017-11-01 11:24:25.534  INFO 8900 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 23.0 (TID 32, localhost, executor driver, partition 2, ANY, 4621 bytes)
2017-11-01 11:24:25.534  INFO 8900 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Running task 0.0 in stage 23.0 (TID 32)
2017-11-01 11:24:25.535  INFO 8900 --- [Executor task launch worker for task 32] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:24:25.535  INFO 8900 --- [Executor task launch worker for task 32] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:24:25.542  INFO 8900 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 23.0 (TID 32). 1488 bytes result sent to driver
2017-11-01 11:24:25.542  INFO 8900 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 23.0 (TID 32) in 8 ms on localhost (executor driver) (1/1)
2017-11-01 11:24:25.542  INFO 8900 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 23.0, whose tasks have all completed, from pool 
2017-11-01 11:24:25.543  INFO 8900 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 23 (take at DayEndCountService.java:184) finished in 0.009 s
2017-11-01 11:24:25.543  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.scheduler.DAGScheduler  : Job 7 finished: take at DayEndCountService.java:184, took 0.016583 s
2017-11-01 11:24:25.544  INFO 8900 --- [http-nio-8080-exec-5] o.s.jetty.server.AbstractConnector       : Stopped Spark@20758206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-11-01 11:24:25.545  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.ui.SparkUI              : Stopped Spark web UI at http://10.7.36.159:4040
2017-11-01 11:24:25.547  INFO 8900 --- [dispatcher-event-loop-3] o.a.s.MapOutputTrackerMasterEndpoint     : MapOutputTrackerMasterEndpoint stopped!
2017-11-01 11:24:25.651  INFO 8900 --- [http-nio-8080-exec-5] o.a.spark.storage.memory.MemoryStore     : MemoryStore cleared
2017-11-01 11:24:25.651  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.storage.BlockManager    : BlockManager stopped
2017-11-01 11:24:25.651  INFO 8900 --- [http-nio-8080-exec-5] o.a.spark.storage.BlockManagerMaster     : BlockManagerMaster stopped
2017-11-01 11:24:25.651  INFO 8900 --- [dispatcher-event-loop-0] rdinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-11-01 11:24:25.654  INFO 8900 --- [http-nio-8080-exec-5] org.apache.spark.SparkContext            : Successfully stopped SparkContext
2017-11-01 11:25:00.146  INFO 7740 --- [main] com.lakala.spark.SparkApp                : Starting SparkApp on user-PC with PID 7740 (D:\IdeaProjects\spark\target\classes started by user in D:\IdeaProjects\spark)
2017-11-01 11:25:00.156  INFO 7740 --- [main] com.lakala.spark.SparkApp                : No active profile set, falling back to default profiles: default
2017-11-01 11:25:00.676  INFO 7740 --- [main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@9cb8225: startup date [Wed Nov 01 11:25:00 CST 2017]; root of context hierarchy
2017-11-01 11:25:02.115  INFO 7740 --- [main] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2017-11-01 11:25:02.836  INFO 7740 --- [main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)
2017-11-01 11:25:02.846  INFO 7740 --- [main] o.apache.catalina.core.StandardService   : Starting service Tomcat
2017-11-01 11:25:02.847  INFO 7740 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet Engine: Apache Tomcat/8.5.11
2017-11-01 11:25:02.966  INFO 7740 --- [localhost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/spark]  : Initializing Spring embedded WebApplicationContext
2017-11-01 11:25:02.966  INFO 7740 --- [localhost-startStop-1] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2294 ms
2017-11-01 11:25:03.128  INFO 7740 --- [localhost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean  : Mapping servlet: 'dispatcherServlet' to [/]
2017-11-01 11:25:03.134  INFO 7740 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'characterEncodingFilter' to: [/*]
2017-11-01 11:25:03.135  INFO 7740 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2017-11-01 11:25:03.135  INFO 7740 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'httpPutFormContentFilter' to: [/*]
2017-11-01 11:25:03.135  INFO 7740 --- [localhost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean   : Mapping filter: 'requestContextFilter' to: [/*]
2017-11-01 11:25:03.583  INFO 7740 --- [main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@9cb8225: startup date [Wed Nov 01 11:25:00 CST 2017]; root of context hierarchy
2017-11-01 11:25:03.651  INFO 7740 --- [main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/countDay]}" onto public java.lang.String com.lakala.spark.controller.DayEndCountController.countDay()
2017-11-01 11:25:03.656  INFO 7740 --- [main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2017-11-01 11:25:03.656  INFO 7740 --- [main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2017-11-01 11:25:03.691  INFO 7740 --- [main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 11:25:03.691  INFO 7740 --- [main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 11:25:03.735  INFO 7740 --- [main] o.s.w.s.handler.SimpleUrlHandlerMapping  : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2017-11-01 11:25:03.769  WARN 7740 --- [main] .t.AbstractTemplateResolverConfiguration : Cannot find template location: classpath:/templates/ (please add some templates or check your Thymeleaf configuration)
2017-11-01 11:25:04.268  INFO 7740 --- [main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup
2017-11-01 11:25:04.330  INFO 7740 --- [main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)
2017-11-01 11:25:04.335  INFO 7740 --- [main] com.lakala.spark.SparkApp                : Started SparkApp in 4.79 seconds (JVM running for 5.445)
2017-11-01 11:25:18.523  INFO 7740 --- [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/spark]  : Initializing Spring FrameworkServlet 'dispatcherServlet'
2017-11-01 11:25:18.523  INFO 7740 --- [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization started
2017-11-01 11:25:18.552  INFO 7740 --- [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : FrameworkServlet 'dispatcherServlet': initialization completed in 29 ms
2017-11-01 11:25:18.893  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Running Spark version 2.2.0
2017-11-01 11:25:18.894  WARN 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Support for Scala 2.10 is deprecated as of Spark 2.1.0
2017-11-01 11:25:19.213  WARN 7740 --- [http-nio-8080-exec-1] org.apache.hadoop.util.NativeCodeLoader  : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-11-01 11:25:19.319  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Submitted application: spark-dayEndCount
2017-11-01 11:25:19.334  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SecurityManager         : Changing view acls to: user
2017-11-01 11:25:19.334  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SecurityManager         : Changing modify acls to: user
2017-11-01 11:25:19.335  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SecurityManager         : Changing view acls groups to: 
2017-11-01 11:25:19.335  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SecurityManager         : Changing modify acls groups to: 
2017-11-01 11:25:19.336  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SecurityManager         : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()
2017-11-01 11:25:19.657  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.util.Utils              : Successfully started service 'sparkDriver' on port 54695.
2017-11-01 11:25:19.673  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkEnv                : Registering MapOutputTracker
2017-11-01 11:25:19.693  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkEnv                : Registering BlockManagerMaster
2017-11-01 11:25:19.697  INFO 7740 --- [http-nio-8080-exec-1] o.a.s.s.BlockManagerMasterEndpoint       : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-11-01 11:25:19.698  INFO 7740 --- [http-nio-8080-exec-1] o.a.s.s.BlockManagerMasterEndpoint       : BlockManagerMasterEndpoint up
2017-11-01 11:25:19.704  INFO 7740 --- [http-nio-8080-exec-1] o.apache.spark.storage.DiskBlockManager  : Created local directory at C:\Windows\Temp\blockmgr-bc1849f9-7217-4d43-8c5a-23122916d9ee
2017-11-01 11:25:19.724  INFO 7740 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : MemoryStore started with capacity 1964.1 MB
2017-11-01 11:25:19.760  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkEnv                : Registering OutputCommitCoordinator
2017-11-01 11:25:19.814  INFO 7740 --- [http-nio-8080-exec-1] org.spark_project.jetty.util.log         : Logging initialized @20924ms
2017-11-01 11:25:19.863  INFO 7740 --- [http-nio-8080-exec-1] org.spark_project.jetty.server.Server    : jetty-9.3.z-SNAPSHOT
2017-11-01 11:25:19.878  INFO 7740 --- [http-nio-8080-exec-1] org.spark_project.jetty.server.Server    : Started @20988ms
2017-11-01 11:25:19.894  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.AbstractConnector       : Started ServerConnector@185d8eb6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-11-01 11:25:19.894  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.util.Utils              : Successfully started service 'SparkUI' on port 4040.
2017-11-01 11:25:19.914  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5bf9bb88{/jobs,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.914  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@229d292c{/jobs/json,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.915  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@71fc5a69{/jobs/job,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.916  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1858fa91{/jobs/job/json,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.916  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@2fcae9d8{/stages,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.917  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5d643474{/stages/json,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.918  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@46fe607c{/stages/stage,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.919  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@3d5023d3{/stages/stage/json,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.919  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@4b2fd727{/stages/pool,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.920  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@395d6a06{/stages/pool/json,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.920  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1a3bae0e{/storage,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.920  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@31cc60fb{/storage/json,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.921  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1f201bc8{/storage/rdd,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.921  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@378e290b{/storage/rdd/json,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.922  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1457e2ef{/environment,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.922  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@d286886{/environment/json,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.923  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1f7cb558{/executors,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.923  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5c4f02b3{/executors/json,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.924  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@29367b4a{/executors/threadDump,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.924  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@76ff4c81{/executors/threadDump/json,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.928  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@698663a7{/static,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.929  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@26c21743{/,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.931  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@40bfea3d{/api,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.932  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@5457095d{/jobs/job/kill,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.932  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@6479438d{/stages/stage/kill,null,AVAILABLE,@Spark}
2017-11-01 11:25:19.934  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.ui.SparkUI              : Bound SparkUI to 0.0.0.0, and started at http://10.7.36.159:4040
2017-11-01 11:25:20.017  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.executor.Executor       : Starting executor ID driver on host localhost
2017-11-01 11:25:20.046  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.util.Utils              : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54705.
2017-11-01 11:25:20.047  INFO 7740 --- [http-nio-8080-exec-1] o.a.s.n.netty.NettyBlockTransferService  : Server created on 10.7.36.159:54705
2017-11-01 11:25:20.048  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.storage.BlockManager    : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-11-01 11:25:20.050  INFO 7740 --- [http-nio-8080-exec-1] o.a.spark.storage.BlockManagerMaster     : Registering BlockManager BlockManagerId(driver, 10.7.36.159, 54705, None)
2017-11-01 11:25:20.054  INFO 7740 --- [dispatcher-event-loop-2] o.a.s.s.BlockManagerMasterEndpoint       : Registering block manager 10.7.36.159:54705 with 1964.1 MB RAM, BlockManagerId(driver, 10.7.36.159, 54705, None)
2017-11-01 11:25:20.060  INFO 7740 --- [http-nio-8080-exec-1] o.a.spark.storage.BlockManagerMaster     : Registered BlockManager BlockManagerId(driver, 10.7.36.159, 54705, None)
2017-11-01 11:25:20.061  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.storage.BlockManager    : Initialized BlockManager: BlockManagerId(driver, 10.7.36.159, 54705, None)
2017-11-01 11:25:20.081  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.handler.ContextHandler  : Started o.s.j.s.ServletContextHandler@1f5c0025{/metrics/json,null,AVAILABLE,@Spark}
2017-11-01 11:25:20.468  INFO 7740 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0 stored as values in memory (estimated size 214.5 KB, free 1963.9 MB)
2017-11-01 11:25:20.547  INFO 7740 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 1963.9 MB)
2017-11-01 11:25:20.550  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_0_piece0 in memory on 10.7.36.159:54705 (size: 20.4 KB, free: 1964.1 MB)
2017-11-01 11:25:20.556  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Created broadcast 0 from textFile at DayEndCountService.java:51
2017-11-01 11:25:20.637  INFO 7740 --- [http-nio-8080-exec-1] o.apache.hadoop.mapred.FileInputFormat   : Total input paths to process : 1
2017-11-01 11:25:20.698  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:72
2017-11-01 11:25:20.711  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 0 (collect at DayEndCountService.java:72) with 1 output partitions
2017-11-01 11:25:20.712  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 0 (collect at DayEndCountService.java:72)
2017-11-01 11:25:20.712  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2017-11-01 11:25:20.714  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:25:20.723  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 0 (MapPartitionsRDD[2] at map at DayEndCountService.java:54), which has no missing parents
2017-11-01 11:25:20.744  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1 stored as values in memory (estimated size 4.0 KB, free 1963.9 MB)
2017-11-01 11:25:20.749  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.9 MB)
2017-11-01 11:25:20.750  INFO 7740 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_1_piece0 in memory on 10.7.36.159:54705 (size: 2.4 KB, free: 1964.1 MB)
2017-11-01 11:25:20.751  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:20.767  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at map at DayEndCountService.java:54) (first 15 tasks are for partitions Vector(0))
2017-11-01 11:25:20.768  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 0.0 with 1 tasks
2017-11-01 11:25:20.810  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4871 bytes)
2017-11-01 11:25:20.816  INFO 7740 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Running task 0.0 in stage 0.0 (TID 0)
2017-11-01 11:25:20.871  INFO 7740 --- [Executor task launch worker for task 0] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TMERINFO/20171101/part-00000:0+1614075
2017-11-01 11:25:20.976  INFO 7740 --- [Executor task launch worker for task 0] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 0.0 (TID 0). 51406 bytes result sent to driver
2017-11-01 11:25:20.994  INFO 7740 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 0.0 (TID 0) in 197 ms on localhost (executor driver) (1/1)
2017-11-01 11:25:20.996  INFO 7740 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 0.0, whose tasks have all completed, from pool 
2017-11-01 11:25:21.001  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 0 (collect at DayEndCountService.java:72) finished in 0.217 s
2017-11-01 11:25:21.009  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 0 finished: collect at DayEndCountService.java:72, took 0.310712 s
2017-11-01 11:25:21.024  INFO 7740 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2 stored as values in memory (estimated size 214.5 KB, free 1963.7 MB)
2017-11-01 11:25:21.035  INFO 7740 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.4 KB, free 1963.6 MB)
2017-11-01 11:25:21.037  INFO 7740 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_2_piece0 in memory on 10.7.36.159:54705 (size: 20.4 KB, free: 1964.1 MB)
2017-11-01 11:25:21.038  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Created broadcast 2 from textFile at DayEndCountService.java:77
2017-11-01 11:25:21.056  INFO 7740 --- [http-nio-8080-exec-1] o.apache.hadoop.mapred.FileInputFormat   : Total input paths to process : 2
2017-11-01 11:25:21.061  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:114
2017-11-01 11:25:21.062  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 1 (collect at DayEndCountService.java:114) with 4 output partitions
2017-11-01 11:25:21.062  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 1 (collect at DayEndCountService.java:114)
2017-11-01 11:25:21.062  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2017-11-01 11:25:21.063  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:25:21.063  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 1 (MapPartitionsRDD[6] at map at DayEndCountService.java:79), which has no missing parents
2017-11-01 11:25:21.065  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:25:21.068  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:25:21.069  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_3_piece0 in memory on 10.7.36.159:54705 (size: 2.4 KB, free: 1964.1 MB)
2017-11-01 11:25:21.069  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:21.070  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at map at DayEndCountService.java:79) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:25:21.070  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 1.0 with 4 tasks
2017-11-01 11:25:21.071  INFO 7740 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:25:21.072  INFO 7740 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Running task 0.0 in stage 1.0 (TID 1)
2017-11-01 11:25:21.076  INFO 7740 --- [Executor task launch worker for task 1] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:0+33554432
2017-11-01 11:25:21.334  INFO 7740 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed broadcast_1_piece0 on 10.7.36.159:54705 in memory (size: 2.4 KB, free: 1964.1 MB)
2017-11-01 11:25:21.898  INFO 7740 --- [Executor task launch worker for task 1] o.a.spark.storage.memory.MemoryStore     : Block taskresult_1 stored as bytes in memory (estimated size 1178.5 KB, free 1962.5 MB)
2017-11-01 11:25:21.900  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_1 in memory on 10.7.36.159:54705 (size: 1178.5 KB, free: 1962.9 MB)
2017-11-01 11:25:21.901  INFO 7740 --- [Executor task launch worker for task 1] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 1.0 (TID 1). 1206769 bytes result sent via BlockManager)
2017-11-01 11:25:21.904  INFO 7740 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:25:21.904  INFO 7740 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Running task 1.0 in stage 1.0 (TID 2)
2017-11-01 11:25:21.908  INFO 7740 --- [Executor task launch worker for task 2] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:33554432+21578018
2017-11-01 11:25:21.944  INFO 7740 --- [task-result-getter-1] o.a.s.n.client.TransportClientFactory    : Successfully created connection to /10.7.36.159:54705 after 26 ms (0 ms spent in bootstraps)
2017-11-01 11:25:22.141  INFO 7740 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 1.0 (TID 1) in 1071 ms on localhost (executor driver) (1/4)
2017-11-01 11:25:22.142  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_1 on 10.7.36.159:54705 in memory (size: 1178.5 KB, free: 1964.1 MB)
2017-11-01 11:25:22.405  INFO 7740 --- [Executor task launch worker for task 2] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 1.0 (TID 2). 224668 bytes result sent to driver
2017-11-01 11:25:22.406  INFO 7740 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:25:22.407  INFO 7740 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Running task 2.0 in stage 1.0 (TID 3)
2017-11-01 11:25:22.415  INFO 7740 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 1.0 (TID 2) in 511 ms on localhost (executor driver) (2/4)
2017-11-01 11:25:22.418  INFO 7740 --- [Executor task launch worker for task 3] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:0+33554432
2017-11-01 11:25:23.207  INFO 7740 --- [Executor task launch worker for task 3] o.a.spark.storage.memory.MemoryStore     : Block taskresult_3 stored as bytes in memory (estimated size 1178.5 KB, free 1962.5 MB)
2017-11-01 11:25:23.210  INFO 7740 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_3 in memory on 10.7.36.159:54705 (size: 1178.5 KB, free: 1962.9 MB)
2017-11-01 11:25:23.210  INFO 7740 --- [Executor task launch worker for task 3] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 1.0 (TID 3). 1206769 bytes result sent via BlockManager)
2017-11-01 11:25:23.212  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:25:23.212  INFO 7740 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Running task 3.0 in stage 1.0 (TID 4)
2017-11-01 11:25:23.220  INFO 7740 --- [Executor task launch worker for task 4] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:33554432+21665160
2017-11-01 11:25:23.280  INFO 7740 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 1.0 (TID 3) in 874 ms on localhost (executor driver) (3/4)
2017-11-01 11:25:23.280  INFO 7740 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_3 on 10.7.36.159:54705 in memory (size: 1178.5 KB, free: 1964.1 MB)
2017-11-01 11:25:23.657  INFO 7740 --- [Executor task launch worker for task 4] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 1.0 (TID 4). 228030 bytes result sent to driver
2017-11-01 11:25:23.666  INFO 7740 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 1.0 (TID 4) in 455 ms on localhost (executor driver) (4/4)
2017-11-01 11:25:23.667  INFO 7740 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 1.0, whose tasks have all completed, from pool 
2017-11-01 11:25:23.667  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 1 (collect at DayEndCountService.java:114) finished in 2.597 s
2017-11-01 11:25:23.668  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 1 finished: collect at DayEndCountService.java:114, took 2.605179 s
2017-11-01 11:25:23.682  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:192
2017-11-01 11:25:23.682  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 2 (collect at DayEndCountService.java:192) with 4 output partitions
2017-11-01 11:25:23.682  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 2 (collect at DayEndCountService.java:192)
2017-11-01 11:25:23.682  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List()
2017-11-01 11:25:23.683  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:25:23.683  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 2 (MapPartitionsRDD[7] at filter at DayEndCountService.java:104), which has no missing parents
2017-11-01 11:25:23.685  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4 stored as values in memory (estimated size 4.3 KB, free 1963.6 MB)
2017-11-01 11:25:23.689  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.5 KB, free 1963.6 MB)
2017-11-01 11:25:23.691  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_4_piece0 in memory on 10.7.36.159:54705 (size: 2.5 KB, free: 1964.1 MB)
2017-11-01 11:25:23.692  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:23.692  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at filter at DayEndCountService.java:104) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:25:23.692  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 2.0 with 4 tasks
2017-11-01 11:25:23.693  INFO 7740 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:25:23.694  INFO 7740 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Running task 0.0 in stage 2.0 (TID 5)
2017-11-01 11:25:23.696  INFO 7740 --- [Executor task launch worker for task 5] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:0+33554432
2017-11-01 11:25:24.477  INFO 7740 --- [Executor task launch worker for task 5] o.a.spark.storage.memory.MemoryStore     : Block taskresult_5 stored as bytes in memory (estimated size 1173.8 KB, free 1962.5 MB)
2017-11-01 11:25:24.480  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_5 in memory on 10.7.36.159:54705 (size: 1173.8 KB, free: 1962.9 MB)
2017-11-01 11:25:24.481  INFO 7740 --- [Executor task launch worker for task 5] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 2.0 (TID 5). 1201954 bytes result sent via BlockManager)
2017-11-01 11:25:24.488  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 2.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:25:24.489  INFO 7740 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Running task 1.0 in stage 2.0 (TID 6)
2017-11-01 11:25:24.499  INFO 7740 --- [Executor task launch worker for task 6] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:33554432+21578018
2017-11-01 11:25:24.574  INFO 7740 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 2.0 (TID 5) in 881 ms on localhost (executor driver) (1/4)
2017-11-01 11:25:24.574  INFO 7740 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_5 on 10.7.36.159:54705 in memory (size: 1173.8 KB, free: 1964.1 MB)
2017-11-01 11:25:24.950  INFO 7740 --- [Executor task launch worker for task 6] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 2.0 (TID 6). 202666 bytes result sent to driver
2017-11-01 11:25:24.950  INFO 7740 --- [dispatcher-event-loop-3] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 2.0 (TID 7, localhost, executor driver, partition 2, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:25:24.951  INFO 7740 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Running task 2.0 in stage 2.0 (TID 7)
2017-11-01 11:25:24.952  INFO 7740 --- [Executor task launch worker for task 7] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:0+33554432
2017-11-01 11:25:24.960  INFO 7740 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 2.0 (TID 6) in 479 ms on localhost (executor driver) (2/4)
2017-11-01 11:25:25.671  INFO 7740 --- [Executor task launch worker for task 7] o.a.spark.storage.memory.MemoryStore     : Block taskresult_7 stored as bytes in memory (estimated size 1173.8 KB, free 1962.5 MB)
2017-11-01 11:25:25.673  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.storage.BlockManagerInfo  : Added taskresult_7 in memory on 10.7.36.159:54705 (size: 1173.8 KB, free: 1962.9 MB)
2017-11-01 11:25:25.673  INFO 7740 --- [Executor task launch worker for task 7] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 2.0 (TID 7). 1201954 bytes result sent via BlockManager)
2017-11-01 11:25:25.674  INFO 7740 --- [dispatcher-event-loop-1] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 2.0 (TID 8, localhost, executor driver, partition 3, PROCESS_LOCAL, 4869 bytes)
2017-11-01 11:25:25.674  INFO 7740 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Running task 3.0 in stage 2.0 (TID 8)
2017-11-01 11:25:25.676  INFO 7740 --- [Executor task launch worker for task 8] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:33554432+21665160
2017-11-01 11:25:25.741  INFO 7740 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 2.0 (TID 7) in 791 ms on localhost (executor driver) (3/4)
2017-11-01 11:25:25.742  INFO 7740 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Removed taskresult_7 on 10.7.36.159:54705 in memory (size: 1173.8 KB, free: 1964.1 MB)
2017-11-01 11:25:26.103  INFO 7740 --- [Executor task launch worker for task 8] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 2.0 (TID 8). 206071 bytes result sent to driver
2017-11-01 11:25:26.110  INFO 7740 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 2.0 (TID 8) in 436 ms on localhost (executor driver) (4/4)
2017-11-01 11:25:26.110  INFO 7740 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 2.0, whose tasks have all completed, from pool 
2017-11-01 11:25:26.111  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 2 (collect at DayEndCountService.java:192) finished in 2.418 s
2017-11-01 11:25:26.111  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 2 finished: collect at DayEndCountService.java:192, took 2.429656 s
2017-11-01 11:25:26.262  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: collect at DayEndCountService.java:252
2017-11-01 11:25:26.267  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 8 (mapToPair at DayEndCountService.java:196)
2017-11-01 11:25:26.267  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 3 (collect at DayEndCountService.java:252) with 4 output partitions
2017-11-01 11:25:26.267  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 4 (collect at DayEndCountService.java:252)
2017-11-01 11:25:26.267  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 3)
2017-11-01 11:25:26.268  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 3)
2017-11-01 11:25:26.269  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at mapToPair at DayEndCountService.java:196), which has no missing parents
2017-11-01 11:25:26.274  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5 stored as values in memory (estimated size 6.1 KB, free 1963.6 MB)
2017-11-01 11:25:26.277  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.2 KB, free 1963.6 MB)
2017-11-01 11:25:26.279  INFO 7740 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_5_piece0 in memory on 10.7.36.159:54705 (size: 3.2 KB, free: 1964.1 MB)
2017-11-01 11:25:26.280  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:26.282  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at mapToPair at DayEndCountService.java:196) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:25:26.282  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 3.0 with 4 tasks
2017-11-01 11:25:26.284  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:25:26.284  INFO 7740 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Running task 0.0 in stage 3.0 (TID 9)
2017-11-01 11:25:26.288  INFO 7740 --- [Executor task launch worker for task 9] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:0+33554432
2017-11-01 11:25:27.232  INFO 7740 --- [Executor task launch worker for task 9] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 3.0 (TID 9). 1026 bytes result sent to driver
2017-11-01 11:25:27.233  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:25:27.233  INFO 7740 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Running task 1.0 in stage 3.0 (TID 10)
2017-11-01 11:25:27.235  INFO 7740 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 3.0 (TID 9) in 952 ms on localhost (executor driver) (1/4)
2017-11-01 11:25:27.235  INFO 7740 --- [Executor task launch worker for task 10] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171031/part-00000:33554432+21578018
2017-11-01 11:25:27.671  INFO 7740 --- [Executor task launch worker for task 10] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 3.0 (TID 10). 940 bytes result sent to driver
2017-11-01 11:25:27.672  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 2, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:25:27.672  INFO 7740 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Running task 2.0 in stage 3.0 (TID 11)
2017-11-01 11:25:27.672  INFO 7740 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 3.0 (TID 10) in 439 ms on localhost (executor driver) (2/4)
2017-11-01 11:25:27.674  INFO 7740 --- [Executor task launch worker for task 11] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:0+33554432
2017-11-01 11:25:28.401  INFO 7740 --- [Executor task launch worker for task 11] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 3.0 (TID 11). 983 bytes result sent to driver
2017-11-01 11:25:28.402  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 3.0 (TID 12, localhost, executor driver, partition 3, PROCESS_LOCAL, 4858 bytes)
2017-11-01 11:25:28.402  INFO 7740 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Running task 3.0 in stage 3.0 (TID 12)
2017-11-01 11:25:28.402  INFO 7740 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 3.0 (TID 11) in 731 ms on localhost (executor driver) (3/4)
2017-11-01 11:25:28.404  INFO 7740 --- [Executor task launch worker for task 12] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TORDER/20171101/part-00000:33554432+21665160
2017-11-01 11:25:28.880  INFO 7740 --- [Executor task launch worker for task 12] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 3.0 (TID 12). 940 bytes result sent to driver
2017-11-01 11:25:28.881  INFO 7740 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 3.0 (TID 12) in 480 ms on localhost (executor driver) (4/4)
2017-11-01 11:25:28.881  INFO 7740 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 3.0, whose tasks have all completed, from pool 
2017-11-01 11:25:28.881  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 3 (mapToPair at DayEndCountService.java:196) finished in 2.598 s
2017-11-01 11:25:28.882  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:25:28.882  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2017-11-01 11:25:28.883  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 4)
2017-11-01 11:25:28.883  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:25:28.886  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 4 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215), which has no missing parents
2017-11-01 11:25:28.891  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6 stored as values in memory (estimated size 7.4 KB, free 1963.6 MB)
2017-11-01 11:25:28.895  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1963.6 MB)
2017-11-01 11:25:28.895  INFO 7740 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_6_piece0 in memory on 10.7.36.159:54705 (size: 3.6 KB, free: 1964.0 MB)
2017-11-01 11:25:28.896  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:28.896  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:25:28.896  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 4.0 with 4 tasks
2017-11-01 11:25:28.899  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 4.0 (TID 13, localhost, executor driver, partition 0, ANY, 4621 bytes)
2017-11-01 11:25:28.900  INFO 7740 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Running task 0.0 in stage 4.0 (TID 13)
2017-11-01 11:25:28.909  INFO 7740 --- [Executor task launch worker for task 13] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:25:28.911  INFO 7740 --- [Executor task launch worker for task 13] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 4 ms
2017-11-01 11:25:29.090  INFO 7740 --- [Executor task launch worker for task 13] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 4.0 (TID 13). 2368 bytes result sent to driver
2017-11-01 11:25:29.091  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 4.0 (TID 14, localhost, executor driver, partition 1, ANY, 4621 bytes)
2017-11-01 11:25:29.092  INFO 7740 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 4.0 (TID 13) in 192 ms on localhost (executor driver) (1/4)
2017-11-01 11:25:29.092  INFO 7740 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Running task 1.0 in stage 4.0 (TID 14)
2017-11-01 11:25:29.094  INFO 7740 --- [Executor task launch worker for task 14] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:25:29.094  INFO 7740 --- [Executor task launch worker for task 14] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:29.247  INFO 7740 --- [Executor task launch worker for task 14] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 4.0 (TID 14). 2376 bytes result sent to driver
2017-11-01 11:25:29.248  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 4.0 (TID 15, localhost, executor driver, partition 2, ANY, 4621 bytes)
2017-11-01 11:25:29.249  INFO 7740 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Running task 2.0 in stage 4.0 (TID 15)
2017-11-01 11:25:29.250  INFO 7740 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 4.0 (TID 14) in 159 ms on localhost (executor driver) (2/4)
2017-11-01 11:25:29.253  INFO 7740 --- [Executor task launch worker for task 15] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:25:29.253  INFO 7740 --- [Executor task launch worker for task 15] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:29.328  INFO 7740 --- [Executor task launch worker for task 15] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 4.0 (TID 15). 2160 bytes result sent to driver
2017-11-01 11:25:29.328  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 4.0 (TID 16, localhost, executor driver, partition 3, ANY, 4621 bytes)
2017-11-01 11:25:29.329  INFO 7740 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Running task 3.0 in stage 4.0 (TID 16)
2017-11-01 11:25:29.329  INFO 7740 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 4.0 (TID 15) in 81 ms on localhost (executor driver) (3/4)
2017-11-01 11:25:29.331  INFO 7740 --- [Executor task launch worker for task 16] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:25:29.331  INFO 7740 --- [Executor task launch worker for task 16] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:29.820  INFO 7740 --- [Executor task launch worker for task 16] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 4.0 (TID 16). 2106 bytes result sent to driver
2017-11-01 11:25:29.820  INFO 7740 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 4.0 (TID 16) in 492 ms on localhost (executor driver) (4/4)
2017-11-01 11:25:29.820  INFO 7740 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 4.0, whose tasks have all completed, from pool 
2017-11-01 11:25:29.820  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 4 (collect at DayEndCountService.java:252) finished in 0.922 s
2017-11-01 11:25:29.821  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 3 finished: collect at DayEndCountService.java:252, took 3.559266 s
2017-11-01 11:25:29.860  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: sortByKey at DayEndCountService.java:178
2017-11-01 11:25:29.864  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 171 bytes
2017-11-01 11:25:29.866  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 11 (mapToPair at DayEndCountService.java:215)
2017-11-01 11:25:29.867  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 3 (mapToPair at DayEndCountService.java:285)
2017-11-01 11:25:29.867  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 4 (sortByKey at DayEndCountService.java:178) with 4 output partitions
2017-11-01 11:25:29.867  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 8 (sortByKey at DayEndCountService.java:178)
2017-11-01 11:25:29.867  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 6, ShuffleMapStage 7)
2017-11-01 11:25:29.868  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 6, ShuffleMapStage 7)
2017-11-01 11:25:29.868  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 6 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215), which has no missing parents
2017-11-01 11:25:29.870  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7 stored as values in memory (estimated size 7.2 KB, free 1963.6 MB)
2017-11-01 11:25:29.873  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.6 KB, free 1963.6 MB)
2017-11-01 11:25:29.875  INFO 7740 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_7_piece0 in memory on 10.7.36.159:54705 (size: 3.6 KB, free: 1964.0 MB)
2017-11-01 11:25:29.875  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:29.876  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[11] at mapToPair at DayEndCountService.java:215) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:25:29.876  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 6.0 with 4 tasks
2017-11-01 11:25:29.877  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 6.0 (TID 17, localhost, executor driver, partition 0, ANY, 4610 bytes)
2017-11-01 11:25:29.877  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 7 (MapPartitionsRDD[3] at mapToPair at DayEndCountService.java:285), which has no missing parents
2017-11-01 11:25:29.877  INFO 7740 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Running task 0.0 in stage 6.0 (TID 17)
2017-11-01 11:25:29.878  INFO 7740 --- [Executor task launch worker for task 17] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:25:29.878  INFO 7740 --- [Executor task launch worker for task 17] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:29.878  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8 stored as values in memory (estimated size 4.9 KB, free 1963.6 MB)
2017-11-01 11:25:29.881  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.8 KB, free 1963.6 MB)
2017-11-01 11:25:29.882  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_8_piece0 in memory on 10.7.36.159:54705 (size: 2.8 KB, free: 1964.0 MB)
2017-11-01 11:25:29.882  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:29.883  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[3] at mapToPair at DayEndCountService.java:285) (first 15 tasks are for partitions Vector(0))
2017-11-01 11:25:29.883  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 7.0 with 1 tasks
2017-11-01 11:25:30.059  INFO 7740 --- [Executor task launch worker for task 17] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 6.0 (TID 17). 1241 bytes result sent to driver
2017-11-01 11:25:30.060  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 6.0 (TID 18, localhost, executor driver, partition 1, ANY, 4610 bytes)
2017-11-01 11:25:30.060  INFO 7740 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Running task 1.0 in stage 6.0 (TID 18)
2017-11-01 11:25:30.060  INFO 7740 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 6.0 (TID 17) in 184 ms on localhost (executor driver) (1/4)
2017-11-01 11:25:30.062  INFO 7740 --- [Executor task launch worker for task 18] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:25:30.062  INFO 7740 --- [Executor task launch worker for task 18] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:30.227  INFO 7740 --- [Executor task launch worker for task 18] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 6.0 (TID 18). 1241 bytes result sent to driver
2017-11-01 11:25:30.228  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 6.0 (TID 19, localhost, executor driver, partition 2, ANY, 4610 bytes)
2017-11-01 11:25:30.228  INFO 7740 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Running task 2.0 in stage 6.0 (TID 19)
2017-11-01 11:25:30.228  INFO 7740 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 6.0 (TID 18) in 169 ms on localhost (executor driver) (2/4)
2017-11-01 11:25:30.230  INFO 7740 --- [Executor task launch worker for task 19] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:25:30.230  INFO 7740 --- [Executor task launch worker for task 19] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:30.322  INFO 7740 --- [Executor task launch worker for task 19] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 6.0 (TID 19). 1241 bytes result sent to driver
2017-11-01 11:25:30.323  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 6.0 (TID 20, localhost, executor driver, partition 3, ANY, 4610 bytes)
2017-11-01 11:25:30.323  INFO 7740 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Running task 3.0 in stage 6.0 (TID 20)
2017-11-01 11:25:30.323  INFO 7740 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 6.0 (TID 19) in 95 ms on localhost (executor driver) (3/4)
2017-11-01 11:25:30.325  INFO 7740 --- [Executor task launch worker for task 20] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:25:30.325  INFO 7740 --- [Executor task launch worker for task 20] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:30.787  INFO 7740 --- [Executor task launch worker for task 20] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 6.0 (TID 20). 1241 bytes result sent to driver
2017-11-01 11:25:30.788  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 7.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 4860 bytes)
2017-11-01 11:25:30.794  INFO 7740 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 6.0 (TID 20) in 470 ms on localhost (executor driver) (4/4)
2017-11-01 11:25:30.794  INFO 7740 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Running task 0.0 in stage 7.0 (TID 21)
2017-11-01 11:25:30.796  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 6 (mapToPair at DayEndCountService.java:215) finished in 0.920 s
2017-11-01 11:25:30.796  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:25:30.796  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set(ShuffleMapStage 7)
2017-11-01 11:25:30.796  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 8)
2017-11-01 11:25:30.796  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:25:30.795  INFO 7740 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 6.0, whose tasks have all completed, from pool 
2017-11-01 11:25:30.798  INFO 7740 --- [Executor task launch worker for task 21] org.apache.spark.rdd.HadoopRDD           : Input split: file:/D:/test/spark/out/TMERINFO/20171101/part-00000:0+1614075
2017-11-01 11:25:30.863  INFO 7740 --- [Executor task launch worker for task 21] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 7.0 (TID 21). 940 bytes result sent to driver
2017-11-01 11:25:30.863  INFO 7740 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 7.0 (TID 21) in 75 ms on localhost (executor driver) (1/1)
2017-11-01 11:25:30.863  INFO 7740 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 7.0, whose tasks have all completed, from pool 
2017-11-01 11:25:30.864  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 7 (mapToPair at DayEndCountService.java:285) finished in 0.981 s
2017-11-01 11:25:30.864  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:25:30.864  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2017-11-01 11:25:30.864  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 8)
2017-11-01 11:25:30.864  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:25:30.864  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 8 (MapPartitionsRDD[18] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:25:30.866  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9 stored as values in memory (estimated size 4.6 KB, free 1963.6 MB)
2017-11-01 11:25:30.928  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.5 KB, free 1963.6 MB)
2017-11-01 11:25:30.933  INFO 7740 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_9_piece0 in memory on 10.7.36.159:54705 (size: 2.5 KB, free: 1964.0 MB)
2017-11-01 11:25:30.935  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:30.936  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ResultStage 8 (MapPartitionsRDD[18] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:25:30.937  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 8.0 with 4 tasks
2017-11-01 11:25:30.940  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 8.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:25:30.942  INFO 7740 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Running task 0.0 in stage 8.0 (TID 22)
2017-11-01 11:25:30.948  INFO 7740 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:25:30.949  INFO 7740 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2017-11-01 11:25:30.949  INFO 7740 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:25:30.950  INFO 7740 --- [Executor task launch worker for task 22] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2017-11-01 11:25:30.997  INFO 7740 --- [Executor task launch worker for task 22] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 8.0 (TID 22). 2778 bytes result sent to driver
2017-11-01 11:25:30.997  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 8.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:25:30.998  INFO 7740 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Running task 1.0 in stage 8.0 (TID 23)
2017-11-01 11:25:30.999  INFO 7740 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:25:30.999  INFO 7740 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:30.999  INFO 7740 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 8.0 (TID 22) in 61 ms on localhost (executor driver) (1/4)
2017-11-01 11:25:30.999  INFO 7740 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:25:31.000  INFO 7740 --- [Executor task launch worker for task 23] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 1 ms
2017-11-01 11:25:31.036  INFO 7740 --- [Executor task launch worker for task 23] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 8.0 (TID 23). 2715 bytes result sent to driver
2017-11-01 11:25:31.036  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 8.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:25:31.036  INFO 7740 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Running task 2.0 in stage 8.0 (TID 24)
2017-11-01 11:25:31.037  INFO 7740 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 8.0 (TID 23) in 40 ms on localhost (executor driver) (2/4)
2017-11-01 11:25:31.039  INFO 7740 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:25:31.039  INFO 7740 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.039  INFO 7740 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:25:31.039  INFO 7740 --- [Executor task launch worker for task 24] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.066  INFO 7740 --- [Executor task launch worker for task 24] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 8.0 (TID 24). 2606 bytes result sent to driver
2017-11-01 11:25:31.067  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 8.0 (TID 25, localhost, executor driver, partition 3, PROCESS_LOCAL, 4684 bytes)
2017-11-01 11:25:31.067  INFO 7740 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 8.0 (TID 24) in 31 ms on localhost (executor driver) (3/4)
2017-11-01 11:25:31.068  INFO 7740 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Running task 3.0 in stage 8.0 (TID 25)
2017-11-01 11:25:31.069  INFO 7740 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:25:31.069  INFO 7740 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.070  INFO 7740 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:25:31.070  INFO 7740 --- [Executor task launch worker for task 25] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.099  INFO 7740 --- [Executor task launch worker for task 25] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 8.0 (TID 25). 2509 bytes result sent to driver
2017-11-01 11:25:31.099  INFO 7740 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 8.0 (TID 25) in 32 ms on localhost (executor driver) (4/4)
2017-11-01 11:25:31.099  INFO 7740 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 8.0, whose tasks have all completed, from pool 
2017-11-01 11:25:31.100  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 8 (sortByKey at DayEndCountService.java:178) finished in 0.163 s
2017-11-01 11:25:31.100  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 4 finished: sortByKey at DayEndCountService.java:178, took 1.240440 s
2017-11-01 11:25:31.124  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: take at DayEndCountService.java:184
2017-11-01 11:25:31.124  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 171 bytes
2017-11-01 11:25:31.127  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 151 bytes
2017-11-01 11:25:31.127  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 168 bytes
2017-11-01 11:25:31.127  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Registering RDD 16 (mapToPair at DayEndCountService.java:160)
2017-11-01 11:25:31.128  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 5 (take at DayEndCountService.java:184) with 1 output partitions
2017-11-01 11:25:31.128  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 13 (take at DayEndCountService.java:184)
2017-11-01 11:25:31.128  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 12)
2017-11-01 11:25:31.128  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List(ShuffleMapStage 12)
2017-11-01 11:25:31.128  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ShuffleMapStage 12 (MapPartitionsRDD[16] at mapToPair at DayEndCountService.java:160), which has no missing parents
2017-11-01 11:25:31.130  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10 stored as values in memory (estimated size 5.1 KB, free 1963.6 MB)
2017-11-01 11:25:31.131  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.9 KB, free 1963.6 MB)
2017-11-01 11:25:31.131  INFO 7740 --- [dispatcher-event-loop-1] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_10_piece0 in memory on 10.7.36.159:54705 (size: 2.9 KB, free: 1964.0 MB)
2017-11-01 11:25:31.132  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:31.132  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[16] at mapToPair at DayEndCountService.java:160) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2017-11-01 11:25:31.132  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 12.0 with 4 tasks
2017-11-01 11:25:31.133  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 12.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:25:31.133  INFO 7740 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Running task 0.0 in stage 12.0 (TID 26)
2017-11-01 11:25:31.135  INFO 7740 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:25:31.135  INFO 7740 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.135  INFO 7740 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:25:31.135  INFO 7740 --- [Executor task launch worker for task 26] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.183  INFO 7740 --- [Executor task launch worker for task 26] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 12.0 (TID 26). 1241 bytes result sent to driver
2017-11-01 11:25:31.184  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 1.0 in stage 12.0 (TID 27, localhost, executor driver, partition 1, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:25:31.184  INFO 7740 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 12.0 (TID 26) in 52 ms on localhost (executor driver) (1/4)
2017-11-01 11:25:31.184  INFO 7740 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Running task 1.0 in stage 12.0 (TID 27)
2017-11-01 11:25:31.186  INFO 7740 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:25:31.186  INFO 7740 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.186  INFO 7740 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:25:31.186  INFO 7740 --- [Executor task launch worker for task 27] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.250  INFO 7740 --- [Executor task launch worker for task 27] org.apache.spark.executor.Executor       : Finished task 1.0 in stage 12.0 (TID 27). 1198 bytes result sent to driver
2017-11-01 11:25:31.251  INFO 7740 --- [dispatcher-event-loop-0] o.apache.spark.scheduler.TaskSetManager  : Starting task 2.0 in stage 12.0 (TID 28, localhost, executor driver, partition 2, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:25:31.251  INFO 7740 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Running task 2.0 in stage 12.0 (TID 28)
2017-11-01 11:25:31.251  INFO 7740 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 1.0 in stage 12.0 (TID 27) in 67 ms on localhost (executor driver) (2/4)
2017-11-01 11:25:31.252  INFO 7740 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:25:31.252  INFO 7740 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.253  INFO 7740 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:25:31.253  INFO 7740 --- [Executor task launch worker for task 28] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.311  INFO 7740 --- [Executor task launch worker for task 28] org.apache.spark.executor.Executor       : Finished task 2.0 in stage 12.0 (TID 28). 1241 bytes result sent to driver
2017-11-01 11:25:31.312  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 3.0 in stage 12.0 (TID 29, localhost, executor driver, partition 3, PROCESS_LOCAL, 4673 bytes)
2017-11-01 11:25:31.312  INFO 7740 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Running task 3.0 in stage 12.0 (TID 29)
2017-11-01 11:25:31.312  INFO 7740 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 2.0 in stage 12.0 (TID 28) in 62 ms on localhost (executor driver) (3/4)
2017-11-01 11:25:31.314  INFO 7740 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 4 blocks
2017-11-01 11:25:31.314  INFO 7740 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.314  INFO 7740 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 1 non-empty blocks out of 1 blocks
2017-11-01 11:25:31.314  INFO 7740 --- [Executor task launch worker for task 29] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.368  INFO 7740 --- [Executor task launch worker for task 29] org.apache.spark.executor.Executor       : Finished task 3.0 in stage 12.0 (TID 29). 1198 bytes result sent to driver
2017-11-01 11:25:31.368  INFO 7740 --- [task-result-getter-1] o.apache.spark.scheduler.TaskSetManager  : Finished task 3.0 in stage 12.0 (TID 29) in 56 ms on localhost (executor driver) (4/4)
2017-11-01 11:25:31.368  INFO 7740 --- [task-result-getter-1] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 12.0, whose tasks have all completed, from pool 
2017-11-01 11:25:31.369  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ShuffleMapStage 12 (mapToPair at DayEndCountService.java:160) finished in 0.237 s
2017-11-01 11:25:31.369  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : looking for newly runnable stages
2017-11-01 11:25:31.369  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : running: Set()
2017-11-01 11:25:31.369  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : waiting: Set(ResultStage 13)
2017-11-01 11:25:31.369  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : failed: Set()
2017-11-01 11:25:31.369  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 13 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:25:31.370  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:25:31.371  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:25:31.373  INFO 7740 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_11_piece0 in memory on 10.7.36.159:54705 (size: 2.4 KB, free: 1964.0 MB)
2017-11-01 11:25:31.374  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:31.374  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 13 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(0))
2017-11-01 11:25:31.374  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 13.0 with 1 tasks
2017-11-01 11:25:31.374  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 13.0 (TID 30, localhost, executor driver, partition 0, ANY, 4621 bytes)
2017-11-01 11:25:31.375  INFO 7740 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Running task 0.0 in stage 13.0 (TID 30)
2017-11-01 11:25:31.376  INFO 7740 --- [Executor task launch worker for task 30] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:25:31.376  INFO 7740 --- [Executor task launch worker for task 30] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.394  INFO 7740 --- [Executor task launch worker for task 30] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 13.0 (TID 30). 4179 bytes result sent to driver
2017-11-01 11:25:31.394  INFO 7740 --- [task-result-getter-2] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 13.0 (TID 30) in 20 ms on localhost (executor driver) (1/1)
2017-11-01 11:25:31.394  INFO 7740 --- [task-result-getter-2] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 13.0, whose tasks have all completed, from pool 
2017-11-01 11:25:31.395  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 13 (take at DayEndCountService.java:184) finished in 0.021 s
2017-11-01 11:25:31.395  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 5 finished: take at DayEndCountService.java:184, took 0.271164 s
2017-11-01 11:25:31.399  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: take at DayEndCountService.java:184
2017-11-01 11:25:31.400  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 0 is 171 bytes
2017-11-01 11:25:31.400  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 2 is 151 bytes
2017-11-01 11:25:31.401  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 1 is 168 bytes
2017-11-01 11:25:31.402  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.MapOutputTrackerMaster  : Size of output statuses for shuffle 3 is 173 bytes
2017-11-01 11:25:31.402  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 6 (take at DayEndCountService.java:184) with 1 output partitions
2017-11-01 11:25:31.402  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 18 (take at DayEndCountService.java:184)
2017-11-01 11:25:31.402  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 17)
2017-11-01 11:25:31.403  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:25:31.403  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 18 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:25:31.404  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:25:31.407  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:25:31.409  INFO 7740 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_12_piece0 in memory on 10.7.36.159:54705 (size: 2.4 KB, free: 1964.0 MB)
2017-11-01 11:25:31.409  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:31.409  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 18 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(1))
2017-11-01 11:25:31.409  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 18.0 with 1 tasks
2017-11-01 11:25:31.410  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 18.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
2017-11-01 11:25:31.410  INFO 7740 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Running task 0.0 in stage 18.0 (TID 31)
2017-11-01 11:25:31.411  INFO 7740 --- [Executor task launch worker for task 31] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 0 non-empty blocks out of 4 blocks
2017-11-01 11:25:31.411  INFO 7740 --- [Executor task launch worker for task 31] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.412  INFO 7740 --- [Executor task launch worker for task 31] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 18.0 (TID 31). 1005 bytes result sent to driver
2017-11-01 11:25:31.413  INFO 7740 --- [task-result-getter-3] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 18.0 (TID 31) in 2 ms on localhost (executor driver) (1/1)
2017-11-01 11:25:31.413  INFO 7740 --- [task-result-getter-3] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 18.0, whose tasks have all completed, from pool 
2017-11-01 11:25:31.413  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 18 (take at DayEndCountService.java:184) finished in 0.004 s
2017-11-01 11:25:31.414  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 6 finished: take at DayEndCountService.java:184, took 0.014010 s
2017-11-01 11:25:31.417  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Starting job: take at DayEndCountService.java:184
2017-11-01 11:25:31.418  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Got job 7 (take at DayEndCountService.java:184) with 1 output partitions
2017-11-01 11:25:31.418  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Final stage: ResultStage 23 (take at DayEndCountService.java:184)
2017-11-01 11:25:31.419  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Parents of final stage: List(ShuffleMapStage 22)
2017-11-01 11:25:31.419  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Missing parents: List()
2017-11-01 11:25:31.419  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting ResultStage 23 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178), which has no missing parents
2017-11-01 11:25:31.420  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13 stored as values in memory (estimated size 4.0 KB, free 1963.6 MB)
2017-11-01 11:25:31.422  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.storage.memory.MemoryStore     : Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.4 KB, free 1963.6 MB)
2017-11-01 11:25:31.422  INFO 7740 --- [dispatcher-event-loop-3] o.apache.spark.storage.BlockManagerInfo  : Added broadcast_13_piece0 in memory on 10.7.36.159:54705 (size: 2.4 KB, free: 1964.0 MB)
2017-11-01 11:25:31.423  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.SparkContext            : Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2017-11-01 11:25:31.423  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : Submitting 1 missing tasks from ResultStage 23 (ShuffledRDD[19] at sortByKey at DayEndCountService.java:178) (first 15 tasks are for partitions Vector(2))
2017-11-01 11:25:31.423  INFO 7740 --- [dag-scheduler-event-loop] o.a.spark.scheduler.TaskSchedulerImpl    : Adding task set 23.0 with 1 tasks
2017-11-01 11:25:31.424  INFO 7740 --- [dispatcher-event-loop-2] o.apache.spark.scheduler.TaskSetManager  : Starting task 0.0 in stage 23.0 (TID 32, localhost, executor driver, partition 2, ANY, 4621 bytes)
2017-11-01 11:25:31.424  INFO 7740 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Running task 0.0 in stage 23.0 (TID 32)
2017-11-01 11:25:31.425  INFO 7740 --- [Executor task launch worker for task 32] o.a.s.s.ShuffleBlockFetcherIterator      : Getting 4 non-empty blocks out of 4 blocks
2017-11-01 11:25:31.425  INFO 7740 --- [Executor task launch worker for task 32] o.a.s.s.ShuffleBlockFetcherIterator      : Started 0 remote fetches in 0 ms
2017-11-01 11:25:31.430  INFO 7740 --- [Executor task launch worker for task 32] org.apache.spark.executor.Executor       : Finished task 0.0 in stage 23.0 (TID 32). 1574 bytes result sent to driver
2017-11-01 11:25:31.431  INFO 7740 --- [task-result-getter-0] o.apache.spark.scheduler.TaskSetManager  : Finished task 0.0 in stage 23.0 (TID 32) in 7 ms on localhost (executor driver) (1/1)
2017-11-01 11:25:31.431  INFO 7740 --- [task-result-getter-0] o.a.spark.scheduler.TaskSchedulerImpl    : Removed TaskSet 23.0, whose tasks have all completed, from pool 
2017-11-01 11:25:31.431  INFO 7740 --- [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler  : ResultStage 23 (take at DayEndCountService.java:184) finished in 0.008 s
2017-11-01 11:25:31.431  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.scheduler.DAGScheduler  : Job 7 finished: take at DayEndCountService.java:184, took 0.014206 s
2017-11-01 11:25:31.437  INFO 7740 --- [http-nio-8080-exec-1] o.s.jetty.server.AbstractConnector       : Stopped Spark@185d8eb6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2017-11-01 11:25:31.439  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.ui.SparkUI              : Stopped Spark web UI at http://10.7.36.159:4040
2017-11-01 11:25:31.454  INFO 7740 --- [dispatcher-event-loop-1] o.a.s.MapOutputTrackerMasterEndpoint     : MapOutputTrackerMasterEndpoint stopped!
2017-11-01 11:25:31.693  INFO 7740 --- [http-nio-8080-exec-1] o.a.spark.storage.memory.MemoryStore     : MemoryStore cleared
2017-11-01 11:25:31.693  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.storage.BlockManager    : BlockManager stopped
2017-11-01 11:25:31.695  INFO 7740 --- [http-nio-8080-exec-1] o.a.spark.storage.BlockManagerMaster     : BlockManagerMaster stopped
2017-11-01 11:25:31.699  INFO 7740 --- [dispatcher-event-loop-0] rdinator$OutputCommitCoordinatorEndpoint : OutputCommitCoordinator stopped!
2017-11-01 11:25:31.704  INFO 7740 --- [http-nio-8080-exec-1] org.apache.spark.SparkContext            : Successfully stopped SparkContext
